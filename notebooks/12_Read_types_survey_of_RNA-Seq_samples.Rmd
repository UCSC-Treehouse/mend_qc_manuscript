---
title: "`r gsub('.Rmd', ' ', gsub('_', ' ', knitr::current_input()))`"
author: "Holly Beale"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
---

# Set submittable print options

```{r}

f_final_draft <- TRUE
notation_text_alpha <- ifelse (f_final_draft, 0, 1 ) 

```


```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE)


library(tidyverse)
library(gridGraphics)
library(RColorBrewer)
library(viridis)
library(ggrepel)
library(cowplot)
library(janitor)

```

# Settings

```{r}

n_samples_to_plot <- 50

f_run_qc <- FALSE
f_label_bars_in_55_sample_plot <- FALSE

library(RColorBrewer)

source_palette <- brewer.pal(12, "Paired")
cb_dark_green <- source_palette[4]
cb_light_green <- source_palette[3]


raw_names_for_read_types_mm <-  c("not_mapped", "Multimapped_read_count", "duplicate_reads", "non_exonic_reads", "MEND")
intermediate_names_for_read_types_mm = c("Not mapped", "Multi-mapped", "Duplicate reads", "Non exonic reads", "MEND")
better_names_for_read_types_mm <- c("Not mapped", "Multi-mapped", "Duplicate", "Non exonic", "MEND")



raw_names_for_read_types <-  c("not_mapped",  "duplicate_reads", "non_exonic_reads", "MEND")
intermediate_names_for_read_types = c("Not mapped", "Duplicate reads", "Non exonic reads", "MEND")
better_names_for_read_types <- c("Not mapped",  "Duplicate", "Non exonic", "MEND")


category_colors <- c(grey(0.5),  cb_light_green, grey(0.7), cb_dark_green) 
names(category_colors) <- intermediate_names_for_read_types


category_colors_mm <- c(grey(0.5), "blue", cb_light_green, grey(0.7), cb_dark_green) 
names(category_colors_mm) <- intermediate_names_for_read_types


multimapper_colors <- c(source_palette[6], source_palette[2] ) 
names(multimapper_colors) <- c("Multi-mapped", "Uniquely mapped")






```

# Load data

```{r}

allCountsRaw <- read_tsv(file.path( "../data/raw_read_survey_results_2019_05_22.txt"), 
                         col_names = c("sample_id", "count_type", "read_count")) %>%
  spread(count_type, read_count) 

samples_in_depth_order = allCountsRaw$sample_id[order(desc(allCountsRaw$total_sequences))]

parent_sample_data <- read_tsv("../data/parent_sample_data_source.tsv") %>% rename(pub_ID = publication_id)

```

# Groom data 

```{r}

complete_counts_raw <- na.omit(allCountsRaw) %>%
  filter(!grepl("TH06", sample_id)) # exclude placeholder QC values from TH06 (we don't have real QC values for these samples)


complete_counts <- complete_counts_raw %>%
  mutate(Mapped_read_count = Multimapped_read_count + Uniquely_mapped_read_count) %>%
  select(-Uniquely_mapped_read_count)

# consider excluding samples in which duplicates may have been removed
# dplyr::filter(!grepl("THR08", sample_id )) # i think duplicates may have been removed from these samples
# nrow (filter(allCountsRaw, grepl("THR08", sample_id )))


# effect of excluding NA, which are usually samples without four measurements
nrow(na.omit(complete_counts))
nrow((complete_counts))


```

## Simplify names

```{r}

read_counts <- complete_counts %>%
  rename(mapped = Mapped_read_count,
         MND = Mapped_non_duplicate_read_count)
    

```

## Calculate fractions of read types

```{r}

orderByTotalReads <- read_counts %>% arrange(desc(total_sequences)) %>%	.$sample_id
read_counts_with_slices <- read_counts %>% 
  arrange(desc(total_sequences)) %>% 
  mutate(pct_MEND = MEND / total_sequences,
         Percent_duplicates = 1 - (MND / mapped), 
         not_mapped = total_sequences - mapped,
         duplicate_reads = mapped - MND,
         non_exonic_reads = MND - MEND,
         sum_slices = MEND + non_exonic_reads + duplicate_reads + not_mapped)

```

## Convert to long form

```{r}

read_counts_with_percentages <- read_counts_with_slices %>% 
			select(sample_id,
			       not_mapped,
			       duplicate_reads,
			       non_exonic_reads,
			       MEND,
			       Multimapped_read_count,
			       mapped,
			       Percent_duplicates,
			       pct_MEND,
			       total_sequences) %>%
			gather(read_type, read_count, not_mapped, duplicate_reads, non_exonic_reads, MEND, Multimapped_read_count) %>%
			mutate(read_type = intermediate_names_for_read_types_mm[match(read_type, raw_names_for_read_types_mm)],
			       read_type = factor(read_type,
			                          levels = intermediate_names_for_read_types_mm),
			       sample_id = factor(sample_id, levels = orderByTotalReads),
			       read_countM = read_count / 1e6,
			       divisor_for_percent = ifelse(read_type=="Multi-mapped", mapped, total_sequences),
			       percent_of_total = read_count / divisor_for_percent)


```


## Identify samples with unusual depths
```{r}

calculate_outliers_thresholds <- function(x, IQR_multFactor=1.5) {
	theseQuartiles=quantile(x, c(1/4,3/4), names=FALSE)
	IQR =theseQuartiles[2]-theseQuartiles[1]
	up_outlier_threshold = theseQuartiles[2] + (IQR_multFactor * IQR)
	down_outlier_threshold = theseQuartiles[1] - (IQR_multFactor * IQR)
	return(c("down" = down_outlier_threshold, "up" = up_outlier_threshold))
	}

outlier_thresholds_for_depth = calculate_outliers_thresholds(read_counts_with_percentages$total_sequences)
# depth_outliers # down outlier threshold is negative; no samples have negative 

read_counts_with_outlier_anno <- read_counts_with_percentages %>%
  mutate(
    total_seq_up_outlier = total_sequences > outlier_thresholds_for_depth["up"],
    total_seq_down_outlier = total_sequences < outlier_thresholds_for_depth["down"]
    )

table(read_counts_with_outlier_anno$total_seq_down_outlier)
table(read_counts_with_outlier_anno$total_seq_up_outlier)

read_counts_without_total_seq_outliers <- read_counts_with_outlier_anno %>%
  filter(!total_seq_down_outlier,
         !total_seq_up_outlier)

print(paste("exclude", length(unique(read_counts_with_percentages$sample_id)) - length(unique(read_counts_without_total_seq_outliers$sample_id)), "samples that were outliers with respect to sequence depth"))
```
# Reference ranges

## Define reference ranges based on mean and sd of samples with typical total read depths and at least 20M MEND reads 

```{r}

read_type_training_set <- read_counts_without_total_seq_outliers %>% 
  group_by(sample_id) %>%
  dplyr::filter(read_countM[read_type == "MEND"] > 20)

read_type_mean_and_sd_20U <- read_type_training_set %>% 
  group_by(read_type) %>% 
  summarize(mean_pct_of_total = mean(percent_of_total), 
            one_sd = sd(percent_of_total),
            mean_minus_one_sd = mean_pct_of_total - one_sd,
            mean_plus_one_sd = mean_pct_of_total + one_sd,
            mean_minus_two_sd = mean_pct_of_total - one_sd * 2,
            mean_plus_two_sd = mean_pct_of_total + one_sd * 2) %>% 
  gather(stat, value, -one_sd, -read_type) %>%
  mutate(stat2 = gsub("^.*two_sd", "two_sd", gsub("^.*one_sd", "one_sd", stat)))

# read_types_with_a_lower_bound <- c("MEND", "Duplicate reads", "Multi-mapped")
read_types_with_a_lower_bound <- unique(read_type_mean_and_sd_20U$read_type)

read_type_pct_thresholds_raw <- read_type_mean_and_sd_20U %>% 
  dplyr::filter(grepl("two_sd", stat)) %>%
  mutate(value2 = ifelse(grepl("minus_two_sd", stat),
                         ifelse(read_type %in% read_types_with_a_lower_bound,
                                value,
                                0),
                         value))
# 
# read_type_pct_thresholds <- read_type_pct_thresholds_raw %>% 
#  select(read_type, stat, value2) %>%
#   spread(stat, value2) %>%
#   rename(min_pct = mean_minus_two_sd, max_pct = mean_plus_two_sd)

read_type_pct_thresholds <- read_type_pct_thresholds_raw %>% 
 select(read_type, stat, value) %>%
  spread(stat, value) %>%
  rename(min_pct = mean_minus_two_sd, max_pct = mean_plus_two_sd)



```

## Identify samples within reference range

```{r}

read_counts_with_thresholds <- left_join(read_counts_with_percentages, read_type_pct_thresholds, by = "read_type") %>%
  mutate(within_limits = ifelse(percent_of_total > min_pct,
                                ifelse(percent_of_total<max_pct,
                                       "within_limits",
                                       "above_limit"),
                                "below_limit"))

samples_within_limits <- read_counts_with_thresholds %>% 
  group_by(sample_id) %>%
  filter(sum(grepl("within_limits", within_limits)) == length(unique(read_counts_with_thresholds$read_type))) %>%
  pull(sample_id) %>% unique

depth_status <- read_counts_with_slices %>%
  select(sample_id, MEND) %>%
  mutate(
    status=ifelse( MEND<10E6,
                   "<10M_MEND_reads",
                   ifelse(MEND<20E6, 
                          "10-20 MEND_reads",
                          ">20M_MEND_reads")
    ),
  all_read_types_within_read_type_limits = sample_id %in% samples_within_limits,
  within_read_type_limits_label = c( "not_WNL", "WNL")[1 + all_read_types_within_read_type_limits]
  )
tabyl(depth_status, within_read_type_limits_label, status)


threshold_codes=c("NM"="Not mapped", "MM"="Multi-mapped", "D"="Duplicate reads", "NE" = "Non exonic reads", "M" = "MEND")

threshold_failure_annotations <- read_counts_with_thresholds %>% 
  mutate(threshold_code = ifelse(within_limits == "within_limits", NA, names(threshold_codes)[match(read_type, threshold_codes)])) %>%
  group_by(sample_id, total_sequences) %>%
  summarize(failed_thresholds = paste(na.omit(threshold_code), collapse=", "))

read_counts_with_limits <- read_counts_with_thresholds %>% 
  left_join(depth_status, by="sample_id") %>%
  left_join(threshold_failure_annotations %>% select(-total_sequences), by="sample_id")
 
```
```{r}

# how many fail
long_fail_status %>%
  pull(sample_id) %>%
  unique %>%
  length

# exclude multimap fails
long_fail_status %>%
  filter (fail_code != "MM") %>%
  pull(sample_id) %>%
  unique %>%
  length

# what does multi-mapper distribution look like?
read_counts_with_limits %>% filter(read_type == "Multi-mapped") %>%
  ggplot + geom_boxplot(aes(y=percent_of_total, x=read_type))

# Why do they fail?
# threshold_codes=c("NM"="Not mapped", "MM"="Multi-mapped", "D"="Duplicate reads", "NE" = "Non exonic reads", "M" = "MEND")


read_counts_with_limits %>% select(sample_id, status) %>% distinct %>% pull(status) %>% table

fail_analysis <- read_counts_with_limits %>% select(sample_id, failed_thresholds) %>% distinct

fail_analysis %>%
  tabyl(failed_thresholds) %>%
  arrange(desc(n))

long_fail_status <- fail_analysis %>% 
  mutate(fail_code = strsplit(failed_thresholds, ", ")) %>%
  unnest(fail_code) %>%
  select(-failed_thresholds) 

long_fail_status %>%
  tabyl(fail_code) %>%
  arrange(percent)


  tabyl(fail_code) %>%
  arrange(percent)


wide_fail_status <- long_fail_status %>%
  mutate(present = TRUE) %>%
  spread(fail_code, present, fill = FALSE)


ggplot(long_fail_status %>% mutate(present = TRUE)) + 
  geom_tile(aes(x=sample_id, y=fail_code, fill = present))

# how many fail codes
fails_per_sample <- wide_fail_status %>% 
  select(-sample_id) %>%
  mutate(n_fails = rowSums(.))

# most failing samples exceeded the reference ranges of more than one type of read.
table(fails_per_sample$n_fails>1)
tabyl(fails_per_sample, n_fails)

```


# Identify a small plottable set of samples
## Pick samples for subset with the same distribution of failure types as main data

```{r}
       
        
# smaller dataset to show individual samples 
# 861 samples in this size range
reasonably_sized_samples <- read_counts_with_limits %>%
  select(sample_id, total_sequences) %>%
  distinct %>%
  filter(total_sequences < 150E6) %>% # the most relevant set, and limiting makes plots intelligible
  pull(sample_id)



# read_counts_with_limits %>% filter(sample_id %in% reasonably_sized_samples) %>% pull(total_sequences) %>% range

# What features does the dataset need to have?

# distribution_in_full_dataset_raw <- rev(sort(table(subset(threshold_failure_annotations, sample_id %in% reasonably_sized_samples)$failed_thresholds)))
distribution_in_full_dataset_raw <- rev(sort(table(threshold_failure_annotations$failed_thresholds)))

# error_distribution <- tibble(error_group_name = gsub("^$", "Pass", names(distribution_in_full_dataset_raw)),
error_distribution <- tibble(error_group_name =names(distribution_in_full_dataset_raw),
       freq_in_full_dataset = as.numeric(distribution_in_full_dataset_raw), 
       desired_freq_in_subset=freq_in_full_dataset*n_samples_to_plot/nrow(threshold_failure_annotations),
       desired_freq_in_subset_integer=round(desired_freq_in_subset),
       curated_target_freq_in_subset = desired_freq_in_subset_integer
       
       ) 

# if rounded fractions don't add to 50, fill
while (sum(error_distribution$curated_target_freq_in_subset)<n_samples_to_plot){
  row_for_passing_samples <- which(error_distribution$error_group_name  %in%  "")[1]
  
  error_distribution$curated_target_freq_in_subset[row_for_passing_samples] = error_distribution$curated_target_freq_in_subset[row_for_passing_samples] + 1
}


# sum(error_distribution$curated_target_freq_in_subset)

random_samples <- apply(error_distribution, 1, function(x){
  # x=error_distribution[2,]
  n_to_sample = round(as.numeric(x["curated_target_freq_in_subset"]))
  threshold_code = as.character(x["error_group_name"])
  if (threshold_code=="Pass") threshold_code = ""
  if (n_to_sample >0){
    set.seed(3)
    samples_to_return <- subset(read_counts_with_limits, 
                                sample_id %in% reasonably_sized_samples & 
                                ! sample_id %in% parent_sample_data$`Treehouse ID` & 
                                  failed_thresholds == threshold_code) %>% 
      select(sample_id) %>%
      distinct %>%
      sample_n(n_to_sample)
      return(samples_to_return)
  }
}
) %>% bind_rows %>% pull(sample_id)

# read_counts_with_limits %>% filter(sample_id %in% random_samples) %>% pull(total_sequences) %>% range

```



## assemble data for small set

```{r}

  

selected_parent_samples <- tibble(THid = parent_sample_data$`Treehouse ID`)

# selected_parent_samples$plot_id = paste0("S", 1:nrow(selected_parent_samples))
selected_parent_samples$plot_id = "*"

set.seed(2)
# random_samples <- read_counts_from_reasonably_sized_samples[sample(1:n_random_samples_needed,n_samples_to_plot),]$sample_id

samples_for_small_dataset <- c(selected_parent_samples$THid, random_samples)

# special_designation=c("other", "From_Fig1")
# special_designation <- c("", "*")
# small_plot_data <- subset(read_counts_with_percentages, sample_id %in% samples_for_small_dataset) %>%

length(samples_for_small_dataset)
length(unique(samples_for_small_dataset))

small_plot_data <- subset(read_counts_with_limits, sample_id %in% samples_for_small_dataset) %>%
  mutate(
    highlight_text = selected_parent_samples$plot_id[match(sample_id, selected_parent_samples$THid)],
    sample_id = factor(sample_id, levels=samples_in_depth_order[samples_in_depth_order %in% sample_id])
  )
# small_plot_data$highlight_text = factor(special_designation[1 + small_plot_data$sample_id %in% example_samples_to_force_into_small_dataset],
#                                        levels = rev(special_designation))
# selected_small_plot_data <- read_counts_with_percentages %>%
selected_small_plot_data <- read_counts_with_limits %>%
  dplyr::filter(sample_id %in% selected_parent_samples$THid)

#table(small_plot_data$read_type
 #     )
# cat(small_plot_data %>% pull(sample_id) %>% unique %>% as.character, file="../data/samples_to_plot.txt")

small_plot_data$not_WNL <- ! small_plot_data$sample_id  %in% samples_within_limits

```


# Rescale data

## Scale MEND to 20M

```{r}

# includes all samples

min_MEND = 20 * 1e6

adjusted_read_counts <- read_counts_with_limits %>% 
  filter(read_type !="Multi-mapped") %>%
  group_by(sample_id) %>% 
  mutate(adjustment_factor = 1 / (read_count[read_type == "MEND"]/min_MEND),
         adjust_read_count = adjustment_factor * read_count,
         total_adjusted_read_count = sum(adjust_read_count))

```

## Calculate and record stats for scaling MEND to all depth thresholds
```{r}

# includes only samples within the reference ranges

proposed_thresholds = c(1,seq(4,48, by = 4))
percentiles_to_query = 0.95 # c(50, 75, 95, 100)/100

#library(purrr)

# remove failed samples
read_counts_within_limits <- read_counts_with_limits %>%
  filter(sample_id %in% samples_within_limits)

proposed_threshold=1
percentile_to_query=0.95

rescale_and_get_percentile <- function(proposed_threshold, percentile_to_query) {
  read_counts_within_limits %>% 
    filter(read_type == "MEND") %>%
    mutate(adjustment_factor = 1 / (read_count / (proposed_threshold * 1e6)),
           adjusted_total = adjustment_factor * total_sequences) %>%
    pull(adjusted_total) %>%
    quantile(percentile_to_query)
}

predictions <- NULL
for (proposed_threshold in proposed_thresholds) {
  for (percentile_to_query in percentiles_to_query){
    predictions <- bind_rows(predictions,
                             tibble(proposed_threshold,
                                    percentile_to_query,
                                    predicted_total_reads = rescale_and_get_percentile(proposed_threshold,
                                                                                       percentile_to_query)))
  }
}


write_tsv(predictions %>% filter(percentile_to_query==0.95),
          "../data/predicted_required_total_reads_within_limits.tsv")



```




# FIGURES

# Fig. 2

### 2A
```{r}
plot_title <- "Total number of reads in a sample does not predict the number of MEND reads"
figure_name <- "read_count_and_fractions_figures_v2"


small_plot_data_no_MM <- subset(small_plot_data, !read_type == "Multi-mapped")


# note negative values in small_plot_data$read_countM, e.g. -0.4817530
p1 <- ggplot(small_plot_data_no_MM) +
  geom_bar(data = small_plot_data_no_MM,
           aes(x = sample_id,
               y = read_countM,
               fill = read_type),
           size = 1,
           stat = "identity") +
  scale_fill_manual("Read type", values = category_colors, labels=better_names_for_read_types) +
  scale_color_grey(end = 0.6) +
  # facet_grid(.~highlight_sample, scales="free_x", space="free") + 
  xlab(paste0("Samples, n=", length(unique(small_plot_data_no_MM$sample_id)))) +
  ylab("Read count (millions)") +
#  ylim(0, 175) +
  geom_text(data=subset(small_plot_data_no_MM, read_type == "MEND"),
                               aes(x = sample_id,
                y = 1 + total_sequences / 1e6,
                label = highlight_text),
            color = "black",
            size = 5) +
  geom_text(data=subset(threshold_failure_annotations, sample_id %in% small_plot_data_no_MM$sample_id),
            aes(x = sample_id,
                y = 1 + total_sequences / 1e6,
                label = failed_thresholds),
            angle=90, hjust=0,
            color = "darkred",
            size=3) +
  # labs(caption= paste(figure_name, Sys.time())) + 
    theme(axis.ticks.x = element_blank(), 
          axis.text.x = element_blank(),
#           legend.position = c(.4,.86)
           legend.position = c(0.65, 0.8)
        #   plot.caption = element_text(hjust = -1)
    ) 
  #geom_text(data=selected_small_plot_data, aes(x=sample_id, y=total_sequences), label="*")

p1
#length(unique(subset(threshold_failure_annotations, sample_id %in% small_plot_data_no_MM$sample_id)$sample_id))
#dim(subset(threshold_failure_annotations, sample_id %in% small_plot_data_no_MM$sample_id))
```



### 2B
```{r}

read_counts_with_percentages_20U <- read_counts_with_percentages %>% 
  group_by(sample_id) %>%
  dplyr::filter(
    read_countM[read_type == "MEND"] > 20,
    !read_type == "Multi-mapped") %>%
  mutate(read_type = factor(read_type, levels = intermediate_names_for_read_types ))

read_type_names <- better_names_for_read_types
names(read_type_names)= names(category_colors)

read_type_labeller <- function(variable,value){
  return(read_type_names[value])
}


p20 <-  ggplot(read_counts_with_percentages_20U) + 
  geom_histogram(aes(x = percent_of_total, fill = read_type)) + 
  geom_vline(data = subset(read_type_mean_and_sd_20U, !read_type == "Multi-mapped"),
             aes(xintercept = value,
                 color = read_type,
                 linetype = stat2)) +
  scale_fill_manual(values = category_colors) +
  scale_color_manual(values = category_colors) +
  facet_wrap(~read_type, nrow=1, labeller=read_type_labeller) 

p20b <- p20 + 
  theme(legend.position = "none") +
  ylab("Samples") + 
  xlab(paste0("Fraction of total reads, n=", length(unique(read_counts_with_percentages_20U$sample_id)))) 

padding_from_line <- -0.04

read_type_pct_thresholds_for_fig2 <- subset(read_type_pct_thresholds, !read_type == "Multi-mapped")  %>%
  gather(threshold, value, -read_type) %>%
  mutate(
    x = ifelse(threshold=="max_pct", value + padding_from_line, value - padding_from_line),
#    y = ifelse(read_type %in% c("Duplicate reads", "MEND"), 200, 50),
    y = 200,
    hjust = ifelse(threshold=="max_pct", "left", "right"),
    label = ifelse(threshold=="max_pct", 
                   paste0("mean\n+ 2sd\n", round(value, 3)),
                   paste0("mean\n- 2sd\n", round(value, 3))
                   )
    )

p20c <- 
  p20b + 
  geom_label(data = read_type_pct_thresholds_for_fig2, 
            aes(x = x, y = y, label = round(value, 3), hjust = hjust)
  ) + 
  scale_x_continuous(breaks = seq(0, 1, by=0.25)) +
  expand_limits(x = c(-0.25, 0.9))

p20c
```




### Combine figures 2A and 2B
```{r}

#p12 <- plot_grid(p1, p20c, labels = c("A", "B"), rel_widths = c(2.5, 1.5) , axis = "x", align = "h")

p12 <- plot_grid(p1, p20c, labels = c("A", "B"), rel_heights = c(4, 1.5), nrow=2 , axis = "y", align = "v")


#title <- ggdraw() +
 # draw_label(plot_title, fontface = 'bold')

fig_file_base <- paste(figure_name, Sys.time())

#plot_output <- plot_grid(title, p12, ncol = 1, rel_heights = c(0.1, 1)) + 
plot_output <-   p12 +
  draw_label(fig_file_base,
             x = 0,
             y = 0,
             vjust = 0,
             hjust = 0,
             size = 10) #, fontface = 'bold')

plot_output
# ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".png"), plot_output, height = 5, width = 12.5)
# ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".png"), plot_output, height = 7, width = 11)
```

## Text related to figure 2

###  ABSTRACT: "The total number of samples analyzed was 1088 from 29 projects"
```{r}

number_of_samples_analyzed <-  nrow(complete_counts_raw)


project_ids <- gsub("TARGET-40.*$", "TARGET-40", gsub("_.*", "", complete_counts_raw$sample_id)) 

number_of_projects <- length(unique(project_ids))

print(paste("The total number of samples analyzed was",number_of_samples_analyzed, "from", number_of_projects, "projects"))
```


###  ABSTRACT: Reference ranges
We addressed variability in sample composition with reference ranges for four types of reads found in sequencing data: unmapped (0-27%); mapped duplicate (0-57%); mapped non exonic (0-27%) and uniquely mapped, exonic, non-duplicate (MEND, 21-77%). 

```{r}

ref_ranges <- subset(read_type_pct_thresholds, !read_type == "Multi-mapped") %>%
  mutate(non_negative_min = ifelse(min_pct<0, 0, min_pct),
         statement = paste0(read_type, " (", round(100*non_negative_min, 0), "-", round(100*max_pct, 0), "%)" ))


paste(ref_ranges$statement, collapse = ";")

```


###  Body
```{r}
number_of_samples_with_more_than_20M_MEND_reads <- nrow(subset(complete_counts_raw, MEND> 20E6))
print(paste( number_of_samples_with_more_than_20M_MEND_reads, "samples have more than 20M MEND reads"))

number_of_samples_within_reference_ranges <- length(samples_within_limits)
print(paste(number_of_samples_within_reference_ranges,"of the", number_of_samples_analyzed, "samples analyzed had values within the reference range.",number_of_samples_analyzed-number_of_samples_within_reference_ranges, "(", round(100*(1-number_of_samples_within_reference_ranges/number_of_samples_analyzed)), "%) did not."))

nrow(subset(complete_counts_raw, MEND< 20E6 & ! sample_id %in% samples_within_limits))

median_num_of_MEND_reads_in_samples_within_limits <- read_counts_with_limits %>% 
  filter(within_limits == "within_limits",
         read_type == "MEND") %>%
  pull(read_countM) %>%
  median
  
print(paste("the median number of MEND reads in these samples was", round(median_num_of_MEND_reads_in_samples_within_limits, 1), "million"))


## Additional observations
# Not all 765 samples in the reference range came from the training set of 831 samples

# 139 of total samples have less than 10M MEND reads
# 251 of total samples have less than 20M MEND reads

# For applying the reference range read type cutoffs, we lose 317 (1082-765) samples

samples_not_in_ref_range = complete_counts_raw$sample_id [ ! complete_counts_raw$sample_id %in% samples_within_limits]

nrow(subset(complete_counts_raw, ( sample_id %in% samples_not_in_ref_range) & MEND <10E6))
nrow(subset(complete_counts_raw, (sample_id %in% samples_not_in_ref_range) & MEND <20E6 & MEND >10E6))

read_counts_with_slices2 <- read_counts_with_slices %>% 
  mutate(
    pct_unmapped = not_mapped / total_sequences,
    pct_non_exonic = non_exonic_reads - MND,
    in_ref_range = sample_id %in% samples_within_limits)


summary(read_counts_with_slices2$pct_unmapped)
# read_counts_with_slices2 %>% arrange(desc(pct_unmapped))

# read_counts_with_slices2 %>%
#   filter(MEND > 20E6) %>%
#   arrange(desc(pct_unmapped))

n_samples_with_gt95pct_unmapped <- sum(read_counts_with_slices2$pct_unmapped > 0.95)

n_samples_with_gt95pct_unmapped <- 
  
  nrow(subset(read_counts_with_slices2, pct_unmapped > 0.95 & MEND > 10E6))
nrow(subset(read_counts_with_slices2, pct_unmapped > 0.95 & MEND > 20E6))
#subset(read_counts_with_slices2, pct_unmapped > 0.95 & MEND > 20E6)$MEND

splitz <- paste("When we apply the reference range cutoffs to the original complete data source, we lose 317 samples. 196 of those samples would be lost to the MEND threshold even if we didn't apply the reference range. By applying the reference range, we exclude 317-196, 121 samples that wouldn't otherwise be excluded. Some are egregious (e.g.", n_samples_with_gt95pct_unmapped, "have less than 95% of reads mapped to the genome")

print(splitz)



# nrow(subset(complete_counts_raw, MEND> 20E6 & sample_id %in% samples_within_limits)) # 710
# 
# total_lost_to_10_MEND_threshold <-  nrow(subset(complete_counts_raw, MEND< 10E6)) # 710
# 
# pct_lost_to_10_MEND_threshold <-  total_lost_to_10_MEND_threshold/number_of_samples_analyzed
# 
# total_lost_to_ref_range <- number_of_samples_analyzed - number_of_samples_within_reference_ranges
# 
# pct_lost_to_ref_range <- total_lost_to_ref_range/number_of_samples_analyzed

```


# Figure 5 - 

```{r}

figure_name <- "predicted_required_total_reads"
fig_file_base <- paste(figure_name, Sys.time())

this_plot_data <- subset(adjusted_read_counts,
                   sample_id %in% samples_for_small_dataset &
                   sample_id %in% samples_within_limits & 
                   ! read_type == "Multi-mapped") %>%
  ungroup %>%
  mutate(sample_id = factor(sample_id, levels=samples_in_depth_order[samples_in_depth_order %in% sample_id]))

this_plot_data_for_labels <- this_plot_data %>%
  filter(sample_id %in% selected_parent_samples$THid,
         read_type == "MEND") 

p <- ggplot(this_plot_data) + 
  geom_bar(aes(x = sample_id, 
               y = adjust_read_count / 1e6, 
               fill = read_type), size = 1, stat = "identity") +
  geom_hline(yintercept = 70, linetype = "dashed") +
  scale_fill_manual("Read type", values = category_colors, labels=better_names_for_read_types) +
  scale_color_grey(end = 0.6) + 
  xlab("Sample") +
  theme(axis.ticks.x = element_blank(), 
        axis.text.x = element_blank()) +
  ylab("Scaled read count (million)") + 
  xlab(paste0("Samples, n=", length(unique(this_plot_data$sample_id)))) +
  geom_text(data=this_plot_data_for_labels,
                               aes(x = sample_id,
                y = 1 + total_adjusted_read_count / 1e6,
                label = "*"),
            color = "black",
            size = 5) + 
  theme(legend.position="none") 


if (f_label_bars_in_55_sample_plot) {
  p <- p +
    geom_text(data=subset(this_plot_data, read_type == "MEND"),
              aes(x = sample_id, y = total_adjusted_read_count / 1e6/2, label = sample_id), 
              angle = 90)
}

###

plot_output <- plot_grid(p) +
  draw_label(paste(figure_name, Sys.time()),
             x = 0, 
             y = 0,             
             vjust = 0, 
             hjust = 0, 
             size = 10) 

plot_output

#ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".png"), plot_output, height = 5, width = 8)
```

This file was saved with the timestamp `r fig_file_base`

## Text around fig 5
```{r}


example_threshold <- 70E6

print(paste(number_of_samples_within_reference_ranges,"samples that had values within the reference range"))

adjusted_MEND_wnl <- 
adjusted_read_counts %>%
filter(sample_id %in% samples_within_limits,
       read_type == "MEND"
       ) 


# t5 is the  nsamples in the reference range require fewer than 70M total reads to contain 20M MEND reads

t5 <- adjusted_MEND_wnl %>% filter(total_adjusted_read_count < example_threshold) %>% nrow
t5/nrow(adjusted_MEND_wnl)

print(paste("All samples in this figure and", round(100*t5/nrow(adjusted_MEND_wnl), 1), "% of the", number_of_samples_within_reference_ranges, "samples in the reference range require fewer than", round(example_threshold/1E6), "M total reads to contain 20M MEND reads (dashed horizontal line)."))


```

# Figure two combined with figure 5

```{r fig.height=11, fig.width=8}


# p12 <- plot_grid(p1, p20c, labels = c("A", "B"), rel_heights = c(4, 1.5), nrow=2 , axis = "y", align = "v")

figure_name <- "read_count_survey"
p125 <- plot_grid(p1, p20c, p, labels = c("A", "B", "C"), rel_heights = c(4, 2, 4), nrow=3, axis = "y", align = "v")

fig_file_base <- paste(figure_name, Sys.time())

plot_output_125 <-   p125 +
  draw_label(fig_file_base,
             x = 0,
             y = 0,
             vjust = 0,
             hjust = 0,
             size = 10,
             alpha = notation_text_alpha) #, fontface = 'bold')

plot_output_125
# ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".png"), plot_output, height = 10, width = 11)


# from fig 5
# plot_output <- plot_grid(p) +
#   draw_label(paste(figure_name, Sys.time()),
#              x = 0, 
#              y = 0,             
#              vjust = 0, 
#              hjust = 0, 
#              size = 10) 
# 
# plot_output


ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".png"), plot_output_125, height = 12, width = 11)


ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".tiff"), plot_output_125, height = 12, width = 11)

```


# Supplemental 2A Figure showing percent multi-mappers per sample

```{r}


plot_title <- "Rate of multimapper reads in selected samples"
figure_name <- "multimappers"


small_plot_data_no_MM <- subset(small_plot_data, !read_type == "Multi-mapped")

m_subtype_data_raw <- complete_counts_raw %>%
  select(sample_id, Multimapped_read_count, Uniquely_mapped_read_count) %>%
  mutate(total_mapped_reads = Multimapped_read_count + Uniquely_mapped_read_count) %>%
  gather(read_type, read_count, -sample_id, -total_mapped_reads) %>%
  mutate(read_countM = read_count/1E6)


samples_in_mapped_order <- complete_counts_raw %>%
  mutate(total_mapped_reads = Multimapped_read_count + Uniquely_mapped_read_count) %>%
  arrange(desc(total_mapped_reads)) %>%
  pull(sample_id)
           
#m_subtype_small_data <- subset(m_subtype_data_raw, sample_id %in% small_plot_data_no_MM$sample_id)


m_subtype_small_data <- subset(m_subtype_data_raw, sample_id %in% small_plot_data_no_MM$sample_id) %>%
  mutate(mm_read_type = gsub("Multimapped_read_count", "Multi-mapped", gsub("Uniquely_mapped_read_count", "Uniquely mapped", read_type)))

m_subtype_small_data$sample_id = factor(m_subtype_small_data$sample_id, levels=samples_in_depth_order[samples_in_depth_order %in% m_subtype_small_data$sample_id])
#m_subtype_small_data$sample_id = factor(m_subtype_small_data$sample_id, levels=samples_in_mapped_order[samples_in_mapped_order %in% m_subtype_small_data$sample_id])



# note negative values in small_plot_data$read_countM, e.g. -0.4817530
#p1 <- 
  

this_plot_data_for_labels <- m_subtype_small_data %>%
  filter(sample_id %in% selected_parent_samples$THid,
         read_type == "Multimapped_read_count") 


threshold_failure_annotations_mm <- threshold_failure_annotations %>%
  filter( sample_id %in% m_subtype_small_data$sample_id) %>%
  left_join(m_subtype_small_data %>% select(sample_id, total_mapped_reads),
            by="sample_id")

  
 p_mm_per_sample <-  ggplot(m_subtype_small_data) +
  geom_bar(data = m_subtype_small_data,
           aes(x = sample_id,
               y = read_countM,
               fill = mm_read_type),
           size = 1,
           stat = "identity") +
#  scale_fill_brewer(palette = "Set1") +
     scale_fill_manual("Subtype of mapped reads", values=multimapper_colors) +
  xlab(paste0("Samples, n=", length(unique(m_subtype_small_data$sample_id)))) +
  ylab("Read count (millions)") +
    theme(axis.ticks.x = element_blank(), 
          axis.text.x = element_blank(),
#          axis.text.x = element_text(size=6, angle = 90, hjust=1),
           legend.position = c(0.45, 0.8)) +
  geom_text(data=this_plot_data_for_labels,
                               aes(x = sample_id,
                y = 1 + total_mapped_reads / 1e6,
                label = "*"),
            color = "black",
            size = 5)+
  geom_text(data=threshold_failure_annotations_mm,
            aes(x = sample_id,
                y = 1 + total_mapped_reads / 1e6,
                label = failed_thresholds),
            angle=90, hjust=0,
            color = "black",
            size=3)
length(small_plot_data_no_MM$sample_id)
length(unique(small_plot_data_no_MM$sample_id))

p_mm_per_sample

```


# Supplemental 2B Figure showing summary of percent multi-mappers

```{r}


plot_title <- "Range of multimapper rate"
figure_name <- "multimappers"




read_counts_with_percentages_20U_mm <- read_counts_with_percentages %>% 
  group_by(sample_id) %>%
  dplyr::filter(
    read_countM[read_type == "MEND"] > 20,
    read_type == "Multi-mapped")

read_type_names <- better_names_for_read_types
names(read_type_names)= names(category_colors)

read_type_labeller <- function(variable,value){
  return(read_type_names[value])
}


p20 <-  ggplot(read_counts_with_percentages_20U_mm) + 
  geom_histogram(aes(x = percent_of_total, fill = read_type)) + 
 #   geom_histogram(aes(x = percent_of_total), fill = "red") + 
  geom_vline(data = subset(read_type_mean_and_sd_20U, read_type == "Multi-mapped"), 
             aes(xintercept = value,
#                 color = read_type,,
                 linetype = stat2),
                  color = "black") +
  scale_fill_manual(values = multimapper_colors) +
  scale_color_manual(values = multimapper_colors)# +
##  scale_fill_brewer(palette = "Spectral") +
#  scale_color_brewer(palette = "Spectral") +
#  facet_wrap(~read_type, nrow=1) 

p20b <- p20 + 
  theme(legend.position = "none") +
  ylab("Samples") + 
  xlab(paste0("Multi-mapped reads as a fraction of mapped reads, n=", length(unique(read_counts_with_percentages_20U_mm$sample_id)))) 

padding_from_line <- -0.04

read_type_pct_thresholds_for_fig2 <- subset(read_type_pct_thresholds, read_type == "Multi-mapped")  %>%
  gather(threshold, value, -read_type) %>%
  mutate(
    x = ifelse(threshold=="max_pct", value + padding_from_line, value - padding_from_line),
#    y = ifelse(read_type %in% c("Duplicate reads", "MEND"), 200, 50),
    y = 200,
    hjust = ifelse(threshold=="max_pct", "left", "right"),
    label = ifelse(threshold=="max_pct", 
                   paste0("mean\n+ 2sd\n", round(value, 3)),
                   paste0("mean\n- 2sd\n", round(value, 3))
                   )
    )

p_mm_summary <- 
  p20b + 
  geom_label(data = read_type_pct_thresholds_for_fig2, 
            aes(x = x, y = y, label = round(value, 3), hjust = hjust)
  ) + 
  scale_x_continuous(breaks = seq(0, 1, by=0.25)) #+
#  expand_limits(x = c(-0.25, 0.9))

p_mm_summary

```

## Combined Fig S2A and S2B
```{r}

figure_name <- "multimapper_survey"
p_S2AB <- plot_grid(p_mm_per_sample, p_mm_summary,labels = c("A", "B"), rel_heights = c(4, 3), nrow=2, axis = "y", align = "v")

fig_file_base <- paste(figure_name, Sys.time())

p_S2AB_labeled <-   p_S2AB +
  draw_label(fig_file_base,
             x = 0,
             y = 0,
             vjust = 0,
             hjust = 0,
             size = 10,
             alpha = notation_text_alpha) #, fontface = 'bold')


p_S2AB_labeled

ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".png"), p_S2AB_labeled, height =8, width = 6)

ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".tiff"), p_S2AB_labeled, height =8, width = 6)

```






# QC


## identify low depth and unbalanced samples
```{r}
# if (f_run_qc) {
plot_info_for_problem_samples <- read_counts_with_limits %>% 
  filter( ! (status==">20M_MEND_reads" & all_read_types_within_read_type_limits)) %>%
  group_by(status, within_read_type_limits_label) %>%
  mutate(
    depth_status_label = paste0(status, ",", within_read_type_limits_label, " (n=", length(unique(sample_id)), ")" )
    ) %>% ungroup %>% 
 mutate(sample_id2 = factor(sample_id, levels=unique(sample_id[order(failed_thresholds)] ) )) 


depth_status_labels_in_order <- unique(plot_info_for_problem_samples$depth_status_label)[c(5, 2, 4, 3, 1)]

plot_info_for_problem_samples$depth_status_label <- factor(plot_info_for_problem_samples$depth_status_label, 
                                                           levels=depth_status_labels_in_order)

# }
```

## QC plot of samples excluded by depth or reference range
```{r fig.height=10}
# if (f_run_qc) {

# detail plot
ggplot(plot_info_for_problem_samples) +
  geom_tile(aes(x=read_type,
                y=sample_id2,
                fill=within_limits)) + 
  facet_grid(depth_status_label ~ ., scales="free_y", space="free",
             labeller = label_wrap_gen(width = 8, multi_line = TRUE)) +
  #facet_wrap(~depth_status_label, ncol=1, scales="free_y") +
  scale_fill_brewer(palette = "Set1") + 
 theme(strip.text.y = element_text(angle = 0),
       axis.text.y = element_blank(),
       axis.text.x = element_text(angle = 90))

# detail table  
plot_info_for_problem_samples %>%
  rename(MEND_depth = status) %>%
  tabyl(read_type, within_limits, MEND_depth) 
  
  
# summary statements
samples_with_lt_10M_MEND_reads <- read_counts_with_limits %>%
  filter(read_type == "MEND",
         read_count<10E6) %>%
  pull (sample_id)

print(paste(length(samples_with_lt_10M_MEND_reads), "samples have fewer than 10M MEND reads"))

samples_with_10_20_M_MEND_reads <- read_counts_with_limits %>%
  filter(read_type == "MEND",
         read_count >= 10E6,
         read_count < 20E6) %>%
  pull (sample_id)

print(paste(length(samples_with_10_20_M_MEND_reads), "samples have 10-20 M MEND reads"))

samples_with_gt_20_M_MEND_reads <- read_counts_with_limits %>%
  filter(read_type == "MEND",
         read_count >= 20E6) %>%
  pull (sample_id)

print(paste(length(samples_with_gt_20_M_MEND_reads), "samples have >20 M MEND reads"))


samples_with_gt_20_M_MEND_reads_not_WNL <- read_counts_with_limits %>%
  filter(read_type == "MEND",
         read_count >= 20E6,
         ! all_read_types_within_read_type_limits) %>%
  pull (sample_id)

print(paste(length(samples_with_gt_20_M_MEND_reads_not_WNL), "of the", length(samples_with_gt_20_M_MEND_reads), "samples with >20 M MEND reads are not within reference range for all five read types"))

print(paste(round(100*length(samples_with_gt_20_M_MEND_reads_not_WNL)/length(samples_with_gt_20_M_MEND_reads), 1), "percent"))

# how many samples would with within limts if not for 




```




```{r}

# question
# how many samples would otherwise pass, but have excessive multi-mappers?
# 43
plot_info_for_problem_samples   %>%
  group_by(sample_id) %>%
  filter(sum(grepl("within_limits", within_limits)) == 4) %>%
  ungroup %>%
  filter(read_type=="Multi-mapped" & within_limits != "within_limits") %>%
  nrow
# 
# how many samples above 20M MEND reads, would otherwise pass, but have excessive multi-mappers?
# 30
plot_info_for_problem_samples   %>%
  filter(status==">20M_MEND_reads") %>%
  group_by(sample_id) %>%
  filter(sum(grepl("within_limits", within_limits)) == 4) %>%
  ungroup %>%
  filter(read_type=="Multi-mapped" & within_limits != "within_limits") %>%
  nrow
# 

plot_info_for_problem_samples %>%
  select(sample_id, status, failed_thresholds) %>%
  distinct %>%
  mutate(failed_thresholds2 = gsub(" ", "", failed_thresholds)) %>%
  tabyl(status, failed_thresholds2)
# }
```

## Characteristics of example set
```{r}
if (f_run_qc) {
# Is the frequency of the reasons for sample failure similar between the example set and the full data set?


# small_plot_data
# read_counts_with_limits
#read_counts_with_limits

# table(small_plot_data$status)/4
# table(read_counts_with_limits$status)/4

# pct failed samples
# 
# read_counts_with_limits %>% 
#   filter(status==">20M_MEND_reads") %>%
#   mutate(percent_pass = sum(all_read_types_within_read_type_limits)/(n())) %>%
#   pull(percent_pass) %>% unique
# 
# 
# small_plot_data %>% 
#   filter(status==">20M_MEND_reads") %>%
#   mutate(percent_pass = sum(all_read_types_within_read_type_limits)/(n())) %>%
#   pull(percent_pass) %>% unique



# to review visually
# subset(read_counts_with_limits, sample_id  %in% subset(small_plot_data, ! not_WNL)$sample_id) %>% 
#   filter(within_limits != "within_limits") %>%
#   select(sample_id, read_type, within_limits) %>%
#   spread(read_type, within_limits) 

# of the samples i've looked at, a below threshold MEND value is always accompanied by a value that exceeds the threshold in another category
}
```
## plot for a single sample

```{r}

if (f_run_qc) {

# s="THR33_1031_S01"  
s = "THR13_0966_S01" 
# s="TH34_1452_S01"
#     
# this_sample_plot_data <- subset(read_counts_with_limits, sample_id == s) 
# 
# 
# %>%
#   ggplot + geom_bar(aes(x=read_count, y=1),
#            stat = "identity") +
#   facet_wrap(~read_type, nrow=1, scale="free_x")

this_sample_plot_data <-  subset(allCountsRaw, sample_id == s) %>% 
  gather(read_measure, read_count, -sample_id) %>% 
  mutate(read_category=ifelse(! read_measure %in% c("Uniquely_mapped_read_count", "Multimapped_read_count"),
                              read_measure,
                              "Mapped_reads")
  )
read_measure_order <- c("total_sequences", "Multimapped_read_count", "Uniquely_mapped_read_count", 
                        "Uniquely_mapped_non_duplicate_read_count", "MEND") # unique(this_sample_plot_data$read_measure)[c(2,5,1,4,3)]

read_cateogry_order <- c("total_sequences", "Mapped_reads", "Uniquely_mapped_non_duplicate_read_count", "MEND") # unique(this_sample_plot_data$read_category)[c(2,1,4,3)]

this_sample_plot_data$read_measure = factor(this_sample_plot_data$read_measure , levels=read_measure_order)

this_sample_plot_data$read_category = factor(this_sample_plot_data$read_category , levels=read_cateogry_order)


ggplot(this_sample_plot_data) + geom_bar(aes(x=read_category , y=read_count/1e6, fill=read_measure),
                                         stat = "identity", pos="stack") +
  facet_wrap(~read_category, nrow=1, scale="free_x") + 
  scale_fill_brewer(palette = "Set1") +
  theme(axis.text.x = element_blank()) +
  theme(strip.background = element_blank(), strip.text = element_blank())


subset(read_counts_with_limits, sample_id == s) %>% select(read_type, min_pct, max_pct, within_limits, percent_of_total)
}  
```

### plot reality checks
```{r}

if (f_run_qc) {
# with random seed 2, it looks like all the fail samples have lower total sequence depth

# In fact, passing samples have the lowest median total sequences count
read_counts_with_limits %>% select(total_sequences, sample_id, failed_thresholds) %>%
  group_by(failed_thresholds) %>%
  summarize(median_total_seq_count = median(total_sequences),
            mean_total_seq_count = mean(total_sequences)
            ) %>% 
  arrange(desc(median_total_seq_count))
  
  
ggplot(read_counts_with_limits)   + geom_histogram(aes(total_sequences)) + facet_wrap(~failed_thresholds)
}  

```


## How much does duplicate fraction vary by depth
```{r}

if (f_run_qc) {
read_counts_with_percentages_20U <- read_counts_with_percentages %>% 
  group_by(sample_id) %>%
  dplyr::filter(
    read_countM[read_type == "MEND"] > 20,
    !read_type == "Multi-mapped")

read_type_names <- better_names_for_read_types
names(read_type_names)= names(category_colors)

read_type_labeller <- function(variable,value){
  return(read_type_names[value])
}


dupe_frac_compare <- read_counts_with_percentages_20U %>% 
  filter(read_type=="Duplicate reads") %>%
  mutate(depth_category = round(total_sequences/10E6))
  
# p20 <-  
  
  ggplot(dupe_frac_compare) + 
  geom_histogram(aes(x = percent_of_total, fill = read_type)) + 
  geom_vline(data = subset(read_type_mean_and_sd_20U, read_type=="Duplicate reads"), 
             aes(xintercept = value,
                 color = read_type,
                 linetype = stat2)) +
  scale_fill_manual(values = category_colors) +
  scale_color_manual(values = category_colors) +
    facet_wrap(~depth_category)
  
ggplot(dupe_frac_compare) + geom_point(aes(x=total_sequences, y=Percent_duplicates, color=pct_MEND * total_sequences >40E6))
}
```