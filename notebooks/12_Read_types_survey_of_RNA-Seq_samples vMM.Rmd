---
title: "`r gsub('.Rmd', ' ', gsub('_', ' ', knitr::current_input()))`"
author: "Holly Beale"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
---

# Include MM at each step

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_knit$set(root.dir = "~/Documents/Dropbox/ucsc/projects/gitCode/drafts_of_umend_qc_publication/")

library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(gridGraphics)
library(RColorBrewer)
library(viridis)
library(ggrepel)
library(cowplot)
library(janitor)

```

# Settings

```{r}

n_samples_to_plot <- 50

library(RColorBrewer)

source_palette <- brewer.pal(12, "Paired")
cb_dark_green <- source_palette[4]
cb_light_green <- source_palette[3]


raw_names_for_read_types <-  c("not_mapped", "Multimapped_read_count", "duplicate_reads", "non_exonic_reads", "UMEND")
intermediate_names_for_read_types = c("Not mapped", "Multi-mapped", "Duplicate reads", "Non exonic reads", "UMEND")
better_names_for_read_types <- c("Not mapped", "Multi-mapped", "Duplicate", "Non exonic", "UMEND")


category_colors <- c(grey(0.5), "blue", cb_light_green, grey(0.7), cb_dark_green) 
names(category_colors) <- intermediate_names_for_read_types

```

# Load data

```{r}

allCountsRaw <- read_tsv(file.path( "../data/raw_read_survey_results_2019_05_13.txt"), 
                         col_names = c("sample_id", "count_type", "read_count")) %>%
  spread(count_type, read_count) %>%
  filter(! grepl("THR08", sample_id),
         ! grepl("THR33", sample_id)
         )

samples_in_depth_order = allCountsRaw$sample_id[order(desc(allCountsRaw$total_sequences))]


parent_sample_data <- read_tsv("../data/parent_sample_data_source.tsv") %>% rename(pub_ID = publication_id)

```

# Groom data 

```{r}

complete_counts_raw <- na.omit(allCountsRaw) %>%
  filter(!grepl("TH06", sample_id)) # exclude placeholder QC values from TH06 (we don't have real QC values for these samples)


complete_counts <- complete_counts_raw %>%
  mutate(Mapped_read_count = Multimapped_read_count + Uniquely_mapped_read_count) %>%
  select(-Uniquely_mapped_read_count)

# consider excluding samples in which duplicates may have been removed
# dplyr::filter(!grepl("THR08", sample_id )) # i think duplicates may have been removed from these samples
# nrow (filter(allCountsRaw, grepl("THR08", sample_id )))


# effect of excluding NA, which are usually samples without four measurements
nrow(na.omit(complete_counts))
nrow((complete_counts))


```

## Simplify names

```{r}

read_counts <- complete_counts %>%
  rename(UM = Mapped_read_count,
         UMND = Uniquely_mapped_non_duplicate_read_count)
    

```

## Calculate fractions of read types

```{r}

orderByTotalReads <- read_counts %>% arrange(desc(total_sequences)) %>%	.$sample_id
read_counts_with_slices <- read_counts %>% 
  arrange(desc(total_sequences)) %>% 
  mutate(pct_UMEND = UMEND / total_sequences,
         Percent_duplicates = 1 - (UMND / UM), 
         not_mapped = total_sequences - UM,
         duplicate_reads = UM - UMND,
         non_exonic_reads = UMND - UMEND,
         sum_slices = UMEND + non_exonic_reads + duplicate_reads + not_mapped)

```

## Convert to long form

```{r}

read_counts_with_percentages <- read_counts_with_slices %>% 
			select(sample_id,
			       not_mapped,
			       duplicate_reads,
			       non_exonic_reads,
			       UMEND,
			       Multimapped_read_count,
			       UM,
			       Percent_duplicates,
			       pct_UMEND,
			       total_sequences) %>%
			gather(read_type, read_count, not_mapped, duplicate_reads, non_exonic_reads, UMEND, Multimapped_read_count) %>%
			mutate(read_type = intermediate_names_for_read_types[match(read_type, raw_names_for_read_types)],
			       read_type = factor(read_type,
			                          levels = intermediate_names_for_read_types),
			       sample_id = factor(sample_id, levels = orderByTotalReads),
			       read_countM = read_count / 1e6,
			       divisor_for_percent = ifelse(read_type=="Multi-mapped", UM, total_sequences),
			       percent_of_total = read_count / divisor_for_percent)


# table(read_counts_with_percentages$read_type)

```

# Define reference ranges based on mean and sd of samples with 20M umend reads

```{r}

read_type_training_set <- read_counts_with_percentages %>% 
  group_by(sample_id) %>%
  dplyr::filter(read_countM[read_type == "UMEND"] > 20)

read_type_mean_and_sd_20U <- read_type_training_set %>% 
  group_by(read_type) %>% 
  summarize(mean_pct_of_total = mean(percent_of_total), 
            one_sd = sd(percent_of_total),
            mean_minus_one_sd = mean_pct_of_total - one_sd,
            mean_plus_one_sd = mean_pct_of_total + one_sd,
            mean_minus_two_sd = mean_pct_of_total - one_sd * 2,
            mean_plus_two_sd = mean_pct_of_total + one_sd * 2) %>% 
  gather(stat, value, -one_sd, -read_type) %>%
  mutate(stat2 = gsub("^.*two_sd", "two_sd", gsub("^.*one_sd", "one_sd", stat)))

# read_types_with_a_lower_bound <- c("UMEND", "Duplicate reads", "Multi-mapped")
read_types_with_a_lower_bound <- unique(read_type_mean_and_sd_20U$read_type)

read_type_pct_thresholds_raw <- read_type_mean_and_sd_20U %>% 
  dplyr::filter(grepl("two_sd", stat)) %>%
  mutate(value2 = ifelse(grepl("minus_two_sd", stat),
                         ifelse(read_type %in% read_types_with_a_lower_bound,
                                value,
                                0),
                         value))
# 
# read_type_pct_thresholds <- read_type_pct_thresholds_raw %>% 
#  select(read_type, stat, value2) %>%
#   spread(stat, value2) %>%
#   rename(min_pct = mean_minus_two_sd, max_pct = mean_plus_two_sd)

read_type_pct_thresholds <- read_type_pct_thresholds_raw %>% 
 select(read_type, stat, value) %>%
  spread(stat, value) %>%
  rename(min_pct = mean_minus_two_sd, max_pct = mean_plus_two_sd)



```

# Identify samples within reference range

```{r}

read_counts_with_thresholds <- left_join(read_counts_with_percentages, read_type_pct_thresholds, by = "read_type") %>%
  mutate(within_limits = ifelse(percent_of_total > min_pct,
                                ifelse(percent_of_total<max_pct,
                                       "within_limits",
                                       "above_limit"),
                                "below_limit"))

samples_within_limits <- read_counts_with_thresholds %>% 
  group_by(sample_id) %>%
  filter(sum(grepl("within_limits", within_limits)) == length(unique(read_counts_with_thresholds$read_type))) %>%
  pull(sample_id) %>% unique

depth_status <- read_counts_with_slices %>%
  select(sample_id, UMEND) %>%
  mutate(
    status=ifelse( UMEND<10E6,
                   "<10M_UMEND_reads",
                   ifelse(UMEND<20E6, 
                          "10-20 UMEND_reads",
                          ">20M_UMEND_reads")
    ),
  all_read_types_within_read_type_limits = sample_id %in% samples_within_limits,
  within_read_type_limits_label = c( "not_WNL", "WNL")[1 + all_read_types_within_read_type_limits]
  )
tabyl(depth_status, within_read_type_limits_label, status)


threshold_codes=c("NM"="Not mapped", "MM"="Multi-mapped", "D"="Duplicate reads", "NE" = "Non exonic reads", "U" = "UMEND")

threshold_failure_annotations <- read_counts_with_thresholds %>% 
  mutate(threshold_code = ifelse(within_limits == "within_limits", NA, names(threshold_codes)[match(read_type, threshold_codes)])) %>%
  group_by(sample_id, total_sequences) %>%
  summarize(failed_thresholds = paste(na.omit(threshold_code), collapse=", "))

read_counts_with_limits <- read_counts_with_thresholds %>% 
  left_join(depth_status, by="sample_id") %>%
  left_join(threshold_failure_annotations %>% select(-total_sequences), by="sample_id")
 
```


# identify low depth and unbalanced samples
```{r}

plot_info_for_problem_samples <- read_counts_with_limits %>% 
  filter( ! (status==">20M_UMEND_reads" & all_read_types_within_read_type_limits)) %>%
  group_by(status, within_read_type_limits_label) %>%
  mutate(
    depth_status_label = paste0(status, ",", within_read_type_limits_label, " (n=", length(unique(sample_id)), ")" )
    ) %>% ungroup %>% 
 mutate(sample_id2 = factor(sample_id, levels=unique(sample_id[order(failed_thresholds)] ) )) 


depth_status_labels_in_order <- unique(plot_info_for_problem_samples$depth_status_label)[c(5, 2, 4, 3, 1)]

plot_info_for_problem_samples$depth_status_label <- factor(plot_info_for_problem_samples$depth_status_label, 
                                                           levels=depth_status_labels_in_order
                                                             )


```

# show QC plot of problem samples
```{r fig.height=10}
ggplot(plot_info_for_problem_samples) +
  geom_tile(aes(x=read_type,
                y=sample_id2,
                fill=within_limits)) + 
  facet_grid(depth_status_label ~ ., scales="free_y", space="free",
             labeller = label_wrap_gen(width = 8, multi_line = TRUE)) +
  #facet_wrap(~depth_status_label, ncol=1, scales="free_y") +
  scale_fill_brewer(palette = "Set1") + 
 theme(strip.text.y = element_text(angle = 0),
       axis.text.y = element_blank(),
       axis.text.x = element_text(angle = 90))

# question
# how many samples would otherwise pass, but have excessive multi-mappers?
# 28
# plot_info_for_problem_samples   %>%
#   group_by(sample_id) %>%
#   filter(sum(grepl("within_limits", within_limits)) == 4) %>%
#   ungroup %>%
#   filter(read_type=="Multi-mapped" & within_limits != "within_limits") 
# 
# plot_info_for_problem_samples %>%
#   select(sample_id, status, failed_thresholds) %>%
#   distinct %>%
#   mutate(failed_thresholds2 = gsub(" ", "", failed_thresholds)) %>%
#   tabyl(status, failed_thresholds2)

```


# Pick samples for subset with the same distribution of failure types as main data

```{r}
       
        
# smaller dataset to show individual samples 
# 861 samples in this size range
reasonably_sized_samples <- read_counts_with_limits %>%
  select(sample_id, total_sequences) %>%
  distinct %>%
  filter(total_sequences < 150E6) %>% # the most relevant set, and limiting makes plots intelligible
  pull(sample_id)



# read_counts_with_limits %>% filter(sample_id %in% reasonably_sized_samples) %>% pull(total_sequences) %>% range

# What features does the dataset need to have?

# distribution_in_full_dataset_raw <- rev(sort(table(subset(threshold_failure_annotations, sample_id %in% reasonably_sized_samples)$failed_thresholds)))
distribution_in_full_dataset_raw <- rev(sort(table(threshold_failure_annotations$failed_thresholds)))

# error_distribution <- tibble(error_group_name = gsub("^$", "Pass", names(distribution_in_full_dataset_raw)),
error_distribution <- tibble(error_group_name =names(distribution_in_full_dataset_raw),
       freq_in_full_dataset = as.numeric(distribution_in_full_dataset_raw), 
       desired_freq_in_subset=freq_in_full_dataset*n_samples_to_plot/nrow(threshold_failure_annotations),
       desired_freq_in_subset_integer=round(desired_freq_in_subset),
       curated_target_freq_in_subset = ifelse(error_group_name %in% c("U", ""), desired_freq_in_subset_integer+1,desired_freq_in_subset_integer) #,
       
       ) # when rounding, the total doesn't add to 50, so i intervened

# test: 
sum(error_distribution$curated_target_freq_in_subset)


random_samples <- apply(error_distribution, 1, function(x){
  # x=error_distribution[2,]
  n_to_sample = round(as.numeric(x["curated_target_freq_in_subset"]))
  threshold_code = as.character(x["error_group_name"])
  if (threshold_code=="Pass") threshold_code = ""
  if (n_to_sample >0){
    set.seed(3)
    subset(read_counts_with_limits, sample_id %in% reasonably_sized_samples & failed_thresholds == threshold_code) %>% 
      select(sample_id) %>%
      sample_n(n_to_sample)
  }
}
) %>% bind_rows %>% pull(sample_id)

# read_counts_with_limits %>% filter(sample_id %in% random_samples) %>% pull(total_sequences) %>% range


```


# assemble data for small set

```{r}

  

selected_parent_samples <- tibble(THid = parent_sample_data$`Treehouse ID`)

# selected_parent_samples$plot_id = paste0("S", 1:nrow(selected_parent_samples))
selected_parent_samples$plot_id = "*"

set.seed(2)
# random_samples <- read_counts_from_reasonably_sized_samples[sample(1:n_random_samples_needed,n_samples_to_plot),]$sample_id

samples_for_small_dataset <- c(selected_parent_samples$THid, random_samples)

# special_designation=c("other", "From_Fig1")
# special_designation <- c("", "*")
# small_plot_data <- subset(read_counts_with_percentages, sample_id %in% samples_for_small_dataset) %>%

small_plot_data <- subset(read_counts_with_limits, sample_id %in% samples_for_small_dataset) %>%
  mutate(
    highlight_text = selected_parent_samples$plot_id[match(sample_id, selected_parent_samples$THid)],
    sample_id = factor(sample_id, levels=samples_in_depth_order[samples_in_depth_order %in% sample_id])
  )
# small_plot_data$highlight_text = factor(special_designation[1 + small_plot_data$sample_id %in% example_samples_to_force_into_small_dataset],
#                                        levels = rev(special_designation))
# selected_small_plot_data <- read_counts_with_percentages %>%
selected_small_plot_data <- read_counts_with_limits %>%
  dplyr::filter(sample_id %in% selected_parent_samples$THid)

#table(small_plot_data$read_type
 #     )
# cat(small_plot_data %>% pull(sample_id) %>% unique %>% as.character, file="../data/samples_to_plot.txt")
```

# Annotate small samples data to indicate those not WNL
```{r}

# Is the frequency of the reasons for sample failure similar between the example set and the full data set?


# small_plot_data
# read_counts_with_limits
#read_counts_with_limits

# table(small_plot_data$status)/4
# table(read_counts_with_limits$status)/4

# pct failed samples
# 
# read_counts_with_limits %>% 
#   filter(status==">20M_UMEND_reads") %>%
#   mutate(percent_pass = sum(all_read_types_within_read_type_limits)/(n())) %>%
#   pull(percent_pass) %>% unique
# 
# 
# small_plot_data %>% 
#   filter(status==">20M_UMEND_reads") %>%
#   mutate(percent_pass = sum(all_read_types_within_read_type_limits)/(n())) %>%
#   pull(percent_pass) %>% unique







small_plot_data$not_WNL <- small_plot_data$sample_id  %in% samples_within_limits

# to review visually
# subset(read_counts_with_limits, sample_id  %in% subset(small_plot_data, ! not_WNL)$sample_id) %>% 
#   filter(within_limits != "within_limits") %>%
#   select(sample_id, read_type, within_limits) %>%
#   spread(read_type, within_limits) 

# of the samples i've looked at, a below threshold UMEND value is always accompanied by a value that exceeds the threshold in another category


```



# Scale UMEND to 20M

```{r}

# includes all samples

min_UMEND = 20 * 1e6

adjusted_read_counts <- read_counts_with_limits %>% 
  filter(read_type !="Multi-mapped") %>%
  group_by(sample_id) %>% 
  mutate(adjustment_factor = 1 / (read_count[read_type == "UMEND"]/min_UMEND),
         adjust_read_count = adjustment_factor * read_count,
         total_adjusted_read_count = sum(adjust_read_count))

```

# Calculate and record stats for scaling UMEND to all depth thresholds
```{r}

# includes only samples within the reference ranges

proposed_thresholds = c(1,seq(4,48, by = 4))
percentiles_to_query = 0.95 # c(50, 75, 95, 100)/100

#library(purrr)

# remove failed samples
read_counts_within_limits <- read_counts_with_limits %>%
  filter(sample_id %in% samples_within_limits)

proposed_threshold=1
percentile_to_query=0.95

rescale_and_get_percentile <- function(proposed_threshold, percentile_to_query) {
  read_counts_within_limits %>% 
    filter(read_type == "UMEND") %>%
    mutate(adjustment_factor = 1 / (read_count / (proposed_threshold * 1e6)),
           adjusted_total = adjustment_factor * total_sequences) %>%
    pull(adjusted_total) %>%
    quantile(percentile_to_query)
}

predictions <- NULL
for (proposed_threshold in proposed_thresholds) {
  for (percentile_to_query in percentiles_to_query){
    predictions <- bind_rows(predictions,
                             tibble(proposed_threshold,
                                    percentile_to_query,
                                    predicted_total_reads = rescale_and_get_percentile(proposed_threshold,
                                                                                       percentile_to_query)))
  }
}


write_tsv(predictions %>% filter(percentile_to_query==0.95),
          "../data/predicted_required_total_reads_within_limits.tsv")



```


# END OF CALCULATIONS

# FIGURES
# Figure 2

### 2A
```{r}
plot_title <- "Total number of reads in a sample does not predict the number of UMEND reads"
figure_name <- "read_count_and_fractions_figures_v2"


small_plot_data_no_MM <- subset(small_plot_data, !read_type == "Multi-mapped")


# note negative values in small_plot_data$read_countM, e.g. -0.4817530
p1 <- ggplot(small_plot_data_no_MM) +
  geom_bar(data = small_plot_data_no_MM,
           aes(x = sample_id,
               y = read_countM,
               fill = read_type),
           size = 1,
           stat = "identity") +
  scale_fill_manual("Read type", values = category_colors, labels=better_names_for_read_types) +
  scale_color_grey(end = 0.6) +
  # facet_grid(.~highlight_sample, scales="free_x", space="free") + 
  xlab(paste0("Samples, n=", length(samples_for_small_dataset))) +
  ylab("Read count (millions)") +
#  ylim(0, 175) +
  geom_text(data=subset(small_plot_data_no_MM, read_type == "UMEND"),
                               aes(x = sample_id,
                y = 1 + total_sequences / 1e6,
                label = highlight_text),
            color = "black",
            size = 5) +
  geom_text(data=subset(threshold_failure_annotations, sample_id %in% small_plot_data_no_MM$sample_id),
            aes(x = sample_id,
                y = 1 + total_sequences / 1e6,
                label = failed_thresholds),
            angle=90, hjust=0,
            color = "darkred",
            size=3) +
  # labs(caption= paste(figure_name, Sys.time())) + 
    theme(axis.ticks.x = element_blank(), 
          axis.text.x = element_blank(),
#           legend.position = c(.4,.86)
           legend.position = c(0.65, 0.8)
        #   plot.caption = element_text(hjust = -1)
    ) 
  #geom_text(data=selected_small_plot_data, aes(x=sample_id, y=total_sequences), label="*")

p1

dim(subset(threshold_failure_annotations, sample_id %in% small_plot_data_no_MM$sample_id))
```

### plot reality checks
```{r}
# with random seed 2, it looks like all the fail samples have lower total sequence depth

# In fact, passing samples have the lowest median total sequences count
read_counts_with_limits %>% select(total_sequences, sample_id, failed_thresholds) %>%
  group_by(failed_thresholds) %>%
  summarize(median_total_seq_count = median(total_sequences),
            mean_total_seq_count = mean(total_sequences)
            ) %>% 
  arrange(desc(median_total_seq_count))
  
  
ggplot(read_counts_with_limits)   + geom_histogram(aes(total_sequences)) + facet_wrap(~failed_thresholds)
  

```


### 2B
```{r}

read_counts_with_percentages_20U <- read_counts_with_percentages %>% 
  group_by(sample_id) %>%
  dplyr::filter(
    read_countM[read_type == "UMEND"] > 20,
    !read_type == "Multi-mapped")

read_type_names <- better_names_for_read_types
names(read_type_names)= names(category_colors)

read_type_labeller <- function(variable,value){
  return(read_type_names[value])
}


p20 <-  ggplot(read_counts_with_percentages_20U) + 
  geom_histogram(aes(x = percent_of_total, fill = read_type)) + 
  geom_vline(data = subset(read_type_mean_and_sd_20U, !read_type == "Multi-mapped"), 
             aes(xintercept = value,
                 color = read_type,
                 linetype = stat2)) +
  scale_fill_manual(values = category_colors) +
  scale_color_manual(values = category_colors) +
  facet_wrap(~read_type, nrow=1, labeller=read_type_labeller) 

p20b <- p20 + 
  theme(legend.position = "none") +
  ylab("Samples") + 
  xlab(paste0("Fraction of total reads, n=", length(unique(read_counts_with_percentages_20U$sample_id)))) 

padding_from_line <- -0.04

read_type_pct_thresholds_for_fig2 <- subset(read_type_pct_thresholds, !read_type == "Multi-mapped")  %>%
  gather(threshold, value, -read_type) %>%
  mutate(
    x = ifelse(threshold=="max_pct", value + padding_from_line, value - padding_from_line),
#    y = ifelse(read_type %in% c("Duplicate reads", "UMEND"), 200, 50),
    y = 200,
    hjust = ifelse(threshold=="max_pct", "left", "right"),
    label = ifelse(threshold=="max_pct", 
                   paste0("mean\n+ 2sd\n", round(value, 3)),
                   paste0("mean\n- 2sd\n", round(value, 3))
                   )
    )

p20c <- 
  p20b + 
  geom_label(data = read_type_pct_thresholds_for_fig2, 
            aes(x = x, y = y, label = round(value, 3), hjust = hjust)
  ) + 
  scale_x_continuous(breaks = seq(0, 1, by=0.25)) +
  expand_limits(x = c(-0.25, 0.9))

p20c
```




### Combine figures 2A and 2B
```{r}

#p12 <- plot_grid(p1, p20c, labels = c("A", "B"), rel_widths = c(2.5, 1.5) , axis = "x", align = "h")

p12 <- plot_grid(p1, p20c, labels = c("A", "B"), rel_heights = c(4, 1.5), nrow=2 , axis = "y", align = "v")


#title <- ggdraw() +
 # draw_label(plot_title, fontface = 'bold')

fig_file_base <- paste(figure_name, Sys.time())

#plot_output <- plot_grid(title, p12, ncol = 1, rel_heights = c(0.1, 1)) + 
plot_output <-   p12 +
  draw_label(fig_file_base,
             x = 0,
             y = 0,
             vjust = 0,
             hjust = 0,
             size = 10) #, fontface = 'bold')

plot_output
# ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".png"), plot_output, height = 5, width = 12.5)
ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".png"), plot_output, height = 7, width = 11)
```

# Text related to figure 2
```{r}

number_of_samples_analyzed <-  nrow(complete_counts_raw)


project_ids <- gsub("TARGET-40.*$", "TARGET-40", gsub("_.*", "", complete_counts_raw$sample_id)) 

number_of_projects <- length(unique(project_ids))

print(paste("The total number of samples analyzed was",number_of_samples_analyzed, "from", number_of_projects, "projects"))


number_of_samples_with_more_than_20M_UMEND_reads <- nrow(subset(complete_counts_raw, UMEND> 20E6))
print(paste( number_of_samples_with_more_than_20M_UMEND_reads, "samples have more than 20M UMEND reads"))

number_of_samples_within_reference_ranges <- length(samples_within_limits)
print(paste(number_of_samples_within_reference_ranges,"of the", number_of_samples_analyzed, "samples analyzed had values within the reference range.",number_of_samples_analyzed-number_of_samples_within_reference_ranges, "(", round(100*(1-number_of_samples_within_reference_ranges/number_of_samples_analyzed)), "%) did not."))

nrow(subset(complete_counts_raw, UMEND< 20E6 & ! sample_id %in% samples_within_limits))

median_num_of_UMEND_reads_in_samples_within_limits <- read_counts_with_limits %>% 
  filter(within_limits == "within_limits",
         read_type == "UMEND") %>%
  pull(read_countM) %>%
  median
  
print(paste("the median number of UMEND reads in these samples was", round(median_num_of_UMEND_reads_in_samples_within_limits, 1), "million"))


## Additional observations
# Not all 765 samples in the reference range came from the training set of 831 samples

# 139 of total samples have less than 10M UMEND reads
# 251 of total samples have less than 20M UMEND reads

# For applying the reference range read type cutoffs, we lose 317 (1082-765) samples

samples_not_in_ref_range = complete_counts_raw$sample_id [ ! complete_counts_raw$sample_id %in% samples_within_limits]

nrow(subset(complete_counts_raw, ( sample_id %in% samples_not_in_ref_range) & UMEND <10E6))
nrow(subset(complete_counts_raw, (sample_id %in% samples_not_in_ref_range) & UMEND <20E6 & UMEND >10E6))

read_counts_with_slices2 <- read_counts_with_slices %>% 
  mutate(
    pct_unmapped = not_mapped / total_sequences,
    pct_non_exonic = non_exonic_reads - UMND,
    in_ref_range = sample_id %in% samples_within_limits)


summary(read_counts_with_slices2$pct_unmapped)
read_counts_with_slices2 %>% arrange(desc(pct_unmapped))

read_counts_with_slices2 %>%
  filter(UMEND > 20E6) %>%
  arrange(desc(pct_unmapped))

n_samples_with_gt95pct_unmapped <- sum(read_counts_with_slices2$pct_unmapped > 0.95)

n_samples_with_gt95pct_unmapped <- 
  
  nrow(subset(read_counts_with_slices2, pct_unmapped > 0.95 & UMEND > 10E6))
nrow(subset(read_counts_with_slices2, pct_unmapped > 0.95 & UMEND > 20E6))
subset(read_counts_with_slices2, pct_unmapped > 0.95 & UMEND > 20E6)$UMEND

splitz <- paste("When we apply the reference range cutoffs to the original complete data source, we lose 317 samples. 196 of those samples would be lost to the UMEND threshold even if we didn't apply the reference range. By applying the reference range, we exclude 317-196, 121 samples that wouldn't otherwise be excluded. Some are egregious (e.g.", n_samples_with_gt95pct_unmapped, "have less than 95% of reads mapped to the genome")

print(splitz)



# nrow(subset(complete_counts_raw, UMEND> 20E6 & sample_id %in% samples_within_limits)) # 710
# 
# total_lost_to_10_UMEND_threshold <-  nrow(subset(complete_counts_raw, UMEND< 10E6)) # 710
# 
# pct_lost_to_10_UMEND_threshold <-  total_lost_to_10_UMEND_threshold/number_of_samples_analyzed
# 
# total_lost_to_ref_range <- number_of_samples_analyzed - number_of_samples_within_reference_ranges
# 
# pct_lost_to_ref_range <- total_lost_to_ref_range/number_of_samples_analyzed

```


# Figure 5 - 

```{r}

figure_name <- "predicted_required_total_reads"
fig_file_base <- paste(figure_name, Sys.time())

this_plot_data <- subset(adjusted_read_counts,
                   sample_id %in% samples_for_small_dataset &
                   sample_id %in% samples_within_limits & 
                   ! read_type == "Multi-mapped") %>%
  ungroup %>%
  mutate(sample_id = factor(sample_id, levels=samples_in_depth_order[samples_in_depth_order %in% sample_id]))

this_plot_data_for_labels <- this_plot_data %>%
  filter(sample_id %in% selected_parent_samples$THid,
         read_type == "UMEND") 

p <- ggplot(this_plot_data) + 
  geom_bar(aes(x = sample_id, 
               y = adjust_read_count / 1e6, 
               fill = read_type), size = 1, stat = "identity") +
  geom_hline(yintercept = 70, linetype = "dashed") +
  scale_fill_manual("Read type", values = category_colors, labels=better_names_for_read_types) +
  scale_color_grey(end = 0.6) + 
  xlab("Sample") +
  theme(axis.ticks.x = element_blank(), 
        axis.text.x = element_blank()) +
  ylab("Scaled read count (million)") + 
  xlab(paste0("Samples, n=", length(unique(this_plot_data$sample_id)))) +
  geom_text(data=this_plot_data_for_labels,
                               aes(x = sample_id,
                y = 1 + total_adjusted_read_count / 1e6,
                label = "*"),
            color = "black",
            size = 5) + 
  theme(legend.position="none") +
  geom_text(data=subset(this_plot_data, read_type == "UMEND"),
            aes(x = sample_id, y = total_adjusted_read_count / 1e6/2, label = sample_id), 
            angle = 90)


###

plot_output <- plot_grid(p) +
  draw_label(paste(figure_name, Sys.time()),
             x = 0, 
             y = 0,             
             vjust = 0, 
             hjust = 0, 
             size = 10) 

plot_output

ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".png"), plot_output, height = 5, width = 8)
```

This file was saved with the timestamp `r fig_file_base`

# Text around fig 5
```{r}


print(paste(number_of_samples_within_reference_ranges,"samples that had values within the reference range"))

adjusted_UMEND_wnl <- 
adjusted_read_counts %>%
filter(sample_id %in% samples_within_limits,
       read_type == "UMEND"
       ) 


# t5 is the  nsamples in the reference range require fewer than 70M total reads to contain 20M UMEND reads

t5 <- adjusted_UMEND_wnl %>% filter(total_adjusted_read_count < 70E6) %>% nrow
t5/nrow(adjusted_UMEND_wnl)

print(paste("All samples in this figure and", round(100*t5/nrow(adjusted_UMEND_wnl)), "% of the", number_of_samples_within_reference_ranges, "samples in the reference range require fewer than 70M total reads to contain 20M UMEND reads (dashed horizontal line)."))


```

# Figure two combined with figure 5

```{r}


# p12 <- plot_grid(p1, p20c, labels = c("A", "B"), rel_heights = c(4, 1.5), nrow=2 , axis = "y", align = "v")

figure_name <- "read_count_survey"
p125 <- plot_grid(p1, p20c, p, labels = c("A", "B", "C"), rel_heights = c(4, 2, 4), nrow=3, axis = "y", align = "v")

fig_file_base <- paste(figure_name, Sys.time())

plot_output_125 <-   p125 +
  draw_label(fig_file_base,
             x = 0,
             y = 0,
             vjust = 0,
             hjust = 0,
             size = 10) #, fontface = 'bold')

# plot_output
# ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".png"), plot_output, height = 10, width = 11)


# from fig 5
# plot_output <- plot_grid(p) +
#   draw_label(paste(figure_name, Sys.time()),
#              x = 0, 
#              y = 0,             
#              vjust = 0, 
#              hjust = 0, 
#              size = 10) 
# 
# plot_output


ggsave(paste0("../figures_and_tables/ ", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".png"), plot_output_125, height = 12, width = 11)


```

#
# Supplemental 2A Figure showing percent multi-mappers
#
```{r}


plot_title <- "Rate of multimapper reads in selected samples"
figure_name <- "multimappers"


small_plot_data_no_MM <- subset(small_plot_data, !read_type == "Multi-mapped")

m_subtype_data_raw <- complete_counts_raw %>%
  select(sample_id, Multimapped_read_count, Uniquely_mapped_read_count) %>%
  gather(read_type, read_count, -sample_id) %>%
  mutate(read_countM = read_count/1E6)


samples_in_mapped_order <- complete_counts_raw %>%
  mutate(total_mapped_reads = Multimapped_read_count + Uniquely_mapped_read_count) %>%
  arrange(desc(total_mapped_reads)) %>%
  pull(sample_id)
           
#m_subtype_small_data <- subset(m_subtype_data_raw, sample_id %in% small_plot_data_no_MM$sample_id)


m_subtype_small_data <- subset(m_subtype_data_raw, sample_id %in% small_plot_data_no_MM$sample_id)

set.seed(1)
m_subtype_small_data <- subset(m_subtype_data_raw, sample_id %in% sample(unique(complete_counts_raw$sample_id), 50)) 

# m_subtype_small_data$sample_id = factor(m_subtype_small_data$sample_id, levels=samples_in_depth_order[samples_in_depth_order %in% m_subtype_small_data$sample_id])
m_subtype_small_data$sample_id = factor(m_subtype_small_data$sample_id, levels=samples_in_mapped_order[samples_in_mapped_order %in% m_subtype_small_data$sample_id])



# note negative values in small_plot_data$read_countM, e.g. -0.4817530
#p1 <- 
  
  
  ggplot(m_subtype_small_data) +
  geom_bar(data = m_subtype_small_data,
           aes(x = sample_id,
               y = read_countM,
               fill = read_type),
           size = 1,
           stat = "identity") +
  scale_fill_brewer(palette = "Set1") +
  xlab(paste0("Samples, n=", length(unique(m_subtype_small_data$sample_id)))) +
  ylab("Read count (millions)") +
    theme(axis.ticks.x = element_blank(), 
#          axis.text.x = element_blank(),
          axis.text.x = element_text(size=6, angle = 90, hjust=1),
           legend.position = c(0.45, 0.8))

```

#
# Supplemental 2A Figure showing percent multi-mappers
#
```{r}


plot_title <- "Range of multimapper rate"
figure_name <- "multimappers"




read_counts_with_percentages_20U <- read_counts_with_percentages %>% 
  group_by(sample_id) %>%
  dplyr::filter(
    read_countM[read_type == "UMEND"] > 20,
    read_type == "Multi-mapped")

read_type_names <- better_names_for_read_types
names(read_type_names)= names(category_colors)

read_type_labeller <- function(variable,value){
  return(read_type_names[value])
}


p20 <-  ggplot(read_counts_with_percentages_20U) + 
  geom_histogram(aes(x = percent_of_total, fill = read_type)) + 
  geom_vline(data = subset(read_type_mean_and_sd_20U, read_type == "Multi-mapped"), 
             aes(xintercept = value,
                 color = read_type,
                 linetype = stat2)) +
  scale_fill_manual(values = category_colors) +
  scale_color_manual(values = category_colors) +
  facet_wrap(~read_type, nrow=1, labeller=read_type_labeller) 

p20b <- p20 + 
  theme(legend.position = "none") +
  ylab("Samples") + 
  xlab(paste0("Fraction of MAPPED reads, n=", length(unique(read_counts_with_percentages_20U$sample_id)))) 

padding_from_line <- -0.04

read_type_pct_thresholds_for_fig2 <- subset(read_type_pct_thresholds, read_type == "Multi-mapped")  %>%
  gather(threshold, value, -read_type) %>%
  mutate(
    x = ifelse(threshold=="max_pct", value + padding_from_line, value - padding_from_line),
#    y = ifelse(read_type %in% c("Duplicate reads", "UMEND"), 200, 50),
    y = 200,
    hjust = ifelse(threshold=="max_pct", "left", "right"),
    label = ifelse(threshold=="max_pct", 
                   paste0("mean\n+ 2sd\n", round(value, 3)),
                   paste0("mean\n- 2sd\n", round(value, 3))
                   )
    )

p20c <- 
  p20b + 
  geom_label(data = read_type_pct_thresholds_for_fig2, 
            aes(x = x, y = y, label = round(value, 3), hjust = hjust)
  ) + 
  scale_x_continuous(breaks = seq(0, 1, by=0.25)) +
  expand_limits(x = c(-0.25, 0.9))

p20c

```








# QC


## plot for a single sample

```{r}



# s="THR33_1031_S01"  
s = "THR13_0966_S01" 
# s="TH34_1452_S01"
#     
# this_sample_plot_data <- subset(read_counts_with_limits, sample_id == s) 
# 
# 
# %>%
#   ggplot + geom_bar(aes(x=read_count, y=1),
#            stat = "identity") +
#   facet_wrap(~read_type, nrow=1, scale="free_x")

this_sample_plot_data <-  subset(allCountsRaw, sample_id == s) %>% 
  gather(read_measure, read_count, -sample_id) %>% 
  mutate(read_category=ifelse(! read_measure %in% c("Uniquely_mapped_read_count", "Multimapped_read_count"),
                              read_measure,
                              "Mapped_reads")
  )
read_measure_order <- c("total_sequences", "Multimapped_read_count", "Uniquely_mapped_read_count", 
                        "Uniquely_mapped_non_duplicate_read_count", "UMEND") # unique(this_sample_plot_data$read_measure)[c(2,5,1,4,3)]

read_cateogry_order <- c("total_sequences", "Mapped_reads", "Uniquely_mapped_non_duplicate_read_count", "UMEND") # unique(this_sample_plot_data$read_category)[c(2,1,4,3)]

this_sample_plot_data$read_measure = factor(this_sample_plot_data$read_measure , levels=read_measure_order)

this_sample_plot_data$read_category = factor(this_sample_plot_data$read_category , levels=read_cateogry_order)


ggplot(this_sample_plot_data) + geom_bar(aes(x=read_category , y=read_count/1e6, fill=read_measure),
                                         stat = "identity", pos="stack") +
  facet_wrap(~read_category, nrow=1, scale="free_x") + 
  scale_fill_brewer(palette = "Set1") +
  theme(axis.text.x = element_blank()) +
  theme(strip.background = element_blank(), strip.text = element_blank())


subset(read_counts_with_limits, sample_id == s) %>% select(read_type, min_pct, max_pct, within_limits, percent_of_total)
  
```

## How much does duplicate fraction vary by depth
```{r}


read_counts_with_percentages_20U <- read_counts_with_percentages %>% 
  group_by(sample_id) %>%
  dplyr::filter(
    read_countM[read_type == "UMEND"] > 20,
    !read_type == "Multi-mapped")

read_type_names <- better_names_for_read_types
names(read_type_names)= names(category_colors)

read_type_labeller <- function(variable,value){
  return(read_type_names[value])
}


dupe_frac_compare <- read_counts_with_percentages_20U %>% 
  filter(read_type=="Duplicate reads") %>%
  mutate(depth_category = round(total_sequences/10E6))
  
# p20 <-  
  
  ggplot(dupe_frac_compare) + 
  geom_histogram(aes(x = percent_of_total, fill = read_type)) + 
  geom_vline(data = subset(read_type_mean_and_sd_20U, read_type=="Duplicate reads"), 
             aes(xintercept = value,
                 color = read_type,
                 linetype = stat2)) +
  scale_fill_manual(values = category_colors) +
  scale_color_manual(values = category_colors) +
    facet_wrap(~depth_category)
  
ggplot(dupe_frac_compare) + geom_point(aes(x=total_sequences, y=Percent_duplicates, color=pct_UMEND * total_sequences >40E6))

```
# Investigate pct dupe distributions at different depths
```{r}

#read_counts_with_percentages_20U
#read_counts_with_limits_dupe_investigation

rcdi <- read_counts_with_limits %>%
  left_join(allCountsRaw %>% select(sample_id, UMEND))  %>% 
  filter(
    read_type=="Duplicate reads",
#    UMEND > 20E6
  ) %>%
  mutate(
    total_depth_category = 10*round(total_sequences/10E6),
    UMEND_depth_category = 10*round(UMEND/10E6),
    project = gsub("[_-].*", "", sample_id)
    )  

rcdi1 <- rcdi %>% 
  filter(total_depth_category %in% 40:60)

rcdi_stats <- rcdi1 %>% 
  group_by(total_depth_category) %>% 
  summarize(mean_pct_of_total = mean(percent_of_total), 
            one_sd = sd(percent_of_total),
            mean_minus_one_sd = mean_pct_of_total - one_sd,
            mean_plus_one_sd = mean_pct_of_total + one_sd,
            mean_minus_two_sd = mean_pct_of_total - one_sd * 2,
            mean_plus_two_sd = mean_pct_of_total + one_sd * 2) %>% 
  select(-one_sd) %>%
  gather(stat, value, -total_depth_category) %>%
  mutate(stat2 = gsub("^.*two_sd", "two_sd", gsub("^.*one_sd", "one_sd", stat)))

# geom_vline(aes(xintercept = mean(speed)),col='red',size=2)+

ggplot(rcdi1) + 
#  geom_histogram(aes(x = percent_of_total, fill = read_type)) + 
  geom_histogram(aes(x = percent_of_total, fill = UMEND>20E6), alpha = 0.5) +   facet_wrap(~total_depth_category) +
#  scale_fill_manual(values = category_colors) +
  scale_color_manual(values = category_colors) +
  geom_vline(data = rcdi_stats, 
             aes(xintercept = value,
                 linetype = stat2))



```
# Investigate who has these low pct dupes
```{r}


rcdi_no2 <- read_counts_with_limits %>%
  left_join(allCountsRaw %>% select(sample_id, UMEND))  %>% 
  filter(
    read_type=="Duplicate reads",
#    UMEND > 20E6
  ) %>%
  mutate(
    total_depth_category = 10*round(total_sequences/10E6),
    UMEND_depth_category = 10*round(UMEND/10E6)
    ) 

#r2a <- subset(rcdi2, Percent_duplicates<0.20) %>%

    sort(table(subset(rcdi, Percent_duplicates<0.20)$project), decreasing = TRUE)

# for each project, what fraction of samples has fewer than 20% duplicates
    
    rcdi %>%
      group_by(project) %>%
      summarize(
        pct_under_20 = sum(Percent_duplicates<0.2)/n(),
        frac_under_20 = paste0(sum(Percent_duplicates<0.2), "/", n()),
        mean = mean(Percent_duplicates)
        ) %>%
      arrange(desc(pct_under_20))
    
    # projects with more than 10 samples
rcdi3_stats <-    rcdi %>%
      group_by(project) %>%
      summarize(
        pct_under_20 = sum(Percent_duplicates<0.2)/n(),
        frac_under_20 = paste0(sum(Percent_duplicates<0.2), "/", n()),
        mean = mean(Percent_duplicates),
        n_samples_in_project = n()
        ) 

ggplot(rcdi3_stats) + geom_histogram(aes(n_samples_in_project))
    

library(forcats)
rcdi4 <- rcdi %>%
  mutate(project = factor(project),
         project_lumped = fct_lump(project, prop = 0.03)
  )

  

ggplot(rcdi4) + geom_histogram(aes(Percent_duplicates, fill=project_lumped)) + ggtitle("pct dupes in larger projects")
    



rcdi4 %>%
         mutate(small_projects = as.character(project)) %>%
         filter(! project %in% levels(project_lumped)) %>%
  ggplot + geom_histogram(aes(Percent_duplicates, fill=project))+ ggtitle("pct dupes in small projects")


    # sort(table(subset(rcdi2, Percent_duplicates<0.20)$project), desc=TRUE)


    
```

## Average duplicate rate per project

```{r}

read_counts_with_slices %>% 
  mutate(project=gsub("[-_].*$", "", sample_id)) %>%
  group_by(project) %>%
  summarize(
    mean_pct_dupe=mean(Percent_duplicates),
    n=n()
    ) %>%
  arrange((mean_pct_dupe))

read_counts_with_slices %>% 
  filter(UMEND>20E6) %>%
  mutate(project=gsub("[-_].*$", "", sample_id)) %>%
  group_by(project) %>%
  summarize(
    mean_pct_dupe=mean(Percent_duplicates),
    n=n()
    ) %>%
  arrange((mean_pct_dupe))



```
