linetype = stat2),
color = "black") +
scale_fill_manual(values = multimapper_colors) +
scale_color_manual(values = multimapper_colors)# +
##  scale_fill_brewer(palette = "Spectral") +
#  scale_color_brewer(palette = "Spectral") +
#  facet_wrap(~read_type, nrow=1)
p20b <- p20 +
theme(legend.position = "none") +
ylab("Samples") +
xlab(paste0("Multi-mapped reads as a fraction of mapped reads, n=", length(unique(read_counts_with_percentages_20U_mm$sample_id))))
padding_from_line <- -0.04
read_type_pct_thresholds_for_fig2 <- subset(read_type_pct_thresholds, read_type == "Multi-mapped")  %>%
gather(threshold, value, -read_type) %>%
mutate(
x = ifelse(threshold=="max_pct", value + padding_from_line, value - padding_from_line),
#    y = ifelse(read_type %in% c("Duplicate reads", "MEND"), 200, 50),
y = 200,
hjust = ifelse(threshold=="max_pct", "left", "right"),
label = ifelse(threshold=="max_pct",
paste0("mean\n+ 2sd\n", round(value, 3)),
paste0("mean\n- 2sd\n", round(value, 3))
)
)
p_mm_summary <-
p20b +
geom_label(data = read_type_pct_thresholds_for_fig2,
aes(x = x, y = y, label = round(value, 3), hjust = hjust)
) +
scale_x_continuous(breaks = seq(0, 1, by=0.25)) #+
#  expand_limits(x = c(-0.25, 0.9))
p_mm_summary
figure_name <- "multimapper_survey"
p_S2AB <- plot_grid(p_mm_per_sample, p_mm_summary,labels = c("A", "B"), rel_heights = c(4, 3), nrow=2, axis = "y", align = "v")
fig_file_base <- paste(figure_name, Sys.time())
p_S2AB_labeled <-   p_S2AB +
draw_label(fig_file_base,
x = 0,
y = 0,
vjust = 0,
hjust = 0,
size = 10,
alpha = notation_text_alpha) #, fontface = 'bold')
p_S2AB_labeled
ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".png"), p_S2AB_labeled, height =8, width = 6)
ggsave(paste0("../figures_and_tables/", gsub(" ", "_", gsub(":", "-", fig_file_base)), ".tiff"), p_S2AB_labeled, height =8, width = 6)
# if (f_run_qc) {
plot_info_for_problem_samples <- read_counts_with_limits %>%
filter( ! (status==">20M_MEND_reads" & all_read_types_within_read_type_limits)) %>%
group_by(status, within_read_type_limits_label) %>%
mutate(
depth_status_label = paste0(status, ",", within_read_type_limits_label, " (n=", length(unique(sample_id)), ")" )
) %>% ungroup %>%
mutate(sample_id2 = factor(sample_id, levels=unique(sample_id[order(failed_thresholds)] ) ))
depth_status_labels_in_order <- unique(plot_info_for_problem_samples$depth_status_label)[c(5, 2, 4, 3, 1)]
plot_info_for_problem_samples$depth_status_label <- factor(plot_info_for_problem_samples$depth_status_label,
levels=depth_status_labels_in_order)
# }
# if (f_run_qc) {
# detail plot
ggplot(plot_info_for_problem_samples) +
geom_tile(aes(x=read_type,
y=sample_id2,
fill=within_limits)) +
facet_grid(depth_status_label ~ ., scales="free_y", space="free",
labeller = label_wrap_gen(width = 8, multi_line = TRUE)) +
#facet_wrap(~depth_status_label, ncol=1, scales="free_y") +
scale_fill_brewer(palette = "Set1") +
theme(strip.text.y = element_text(angle = 0),
axis.text.y = element_blank(),
axis.text.x = element_text(angle = 90))
# detail table
plot_info_for_problem_samples %>%
rename(MEND_depth = status) %>%
tabyl(read_type, within_limits, MEND_depth)
# summary statements
samples_with_lt_10M_MEND_reads <- read_counts_with_limits %>%
filter(read_type == "MEND",
read_count<10E6) %>%
pull (sample_id)
print(paste(length(samples_with_lt_10M_MEND_reads), "samples have fewer than 10M MEND reads"))
samples_with_10_20_M_MEND_reads <- read_counts_with_limits %>%
filter(read_type == "MEND",
read_count >= 10E6,
read_count < 20E6) %>%
pull (sample_id)
print(paste(length(samples_with_10_20_M_MEND_reads), "samples have 10-20 M MEND reads"))
samples_with_gt_20_M_MEND_reads <- read_counts_with_limits %>%
filter(read_type == "MEND",
read_count >= 20E6) %>%
pull (sample_id)
print(paste(length(samples_with_gt_20_M_MEND_reads), "samples have >20 M MEND reads"))
samples_with_gt_20_M_MEND_reads_not_WNL <- read_counts_with_limits %>%
filter(read_type == "MEND",
read_count >= 20E6,
! all_read_types_within_read_type_limits) %>%
pull (sample_id)
print(paste(length(samples_with_gt_20_M_MEND_reads_not_WNL), "of the", length(samples_with_gt_20_M_MEND_reads), "samples with >20 M MEND reads are not within reference range for all five read types"))
print(paste(round(100*length(samples_with_gt_20_M_MEND_reads_not_WNL)/length(samples_with_gt_20_M_MEND_reads), 1), "percent"))
# how many samples would with within limts if not for
# question
# how many samples would otherwise pass, but have excessive multi-mappers?
# 43
plot_info_for_problem_samples   %>%
group_by(sample_id) %>%
filter(sum(grepl("within_limits", within_limits)) == 4) %>%
ungroup %>%
filter(read_type=="Multi-mapped" & within_limits != "within_limits") %>%
nrow
#
# how many samples above 20M MEND reads, would otherwise pass, but have excessive multi-mappers?
# 30
plot_info_for_problem_samples   %>%
filter(status==">20M_MEND_reads") %>%
group_by(sample_id) %>%
filter(sum(grepl("within_limits", within_limits)) == 4) %>%
ungroup %>%
filter(read_type=="Multi-mapped" & within_limits != "within_limits") %>%
nrow
#
plot_info_for_problem_samples %>%
select(sample_id, status, failed_thresholds) %>%
distinct %>%
mutate(failed_thresholds2 = gsub(" ", "", failed_thresholds)) %>%
tabyl(status, failed_thresholds2)
# }
if (f_run_qc) {
# Is the frequency of the reasons for sample failure similar between the example set and the full data set?
# small_plot_data
# read_counts_with_limits
#read_counts_with_limits
# table(small_plot_data$status)/4
# table(read_counts_with_limits$status)/4
# pct failed samples
#
# read_counts_with_limits %>%
#   filter(status==">20M_MEND_reads") %>%
#   mutate(percent_pass = sum(all_read_types_within_read_type_limits)/(n())) %>%
#   pull(percent_pass) %>% unique
#
#
# small_plot_data %>%
#   filter(status==">20M_MEND_reads") %>%
#   mutate(percent_pass = sum(all_read_types_within_read_type_limits)/(n())) %>%
#   pull(percent_pass) %>% unique
# to review visually
# subset(read_counts_with_limits, sample_id  %in% subset(small_plot_data, ! not_WNL)$sample_id) %>%
#   filter(within_limits != "within_limits") %>%
#   select(sample_id, read_type, within_limits) %>%
#   spread(read_type, within_limits)
# of the samples i've looked at, a below threshold MEND value is always accompanied by a value that exceeds the threshold in another category
}
if (f_run_qc) {
# s="THR33_1031_S01"
s = "THR13_0966_S01"
# s="TH34_1452_S01"
#
# this_sample_plot_data <- subset(read_counts_with_limits, sample_id == s)
#
#
# %>%
#   ggplot + geom_bar(aes(x=read_count, y=1),
#            stat = "identity") +
#   facet_wrap(~read_type, nrow=1, scale="free_x")
this_sample_plot_data <-  subset(allCountsRaw, sample_id == s) %>%
gather(read_measure, read_count, -sample_id) %>%
mutate(read_category=ifelse(! read_measure %in% c("Uniquely_mapped_read_count", "Multimapped_read_count"),
read_measure,
"Mapped_reads")
)
read_measure_order <- c("total_sequences", "Multimapped_read_count", "Uniquely_mapped_read_count",
"Uniquely_mapped_non_duplicate_read_count", "MEND") # unique(this_sample_plot_data$read_measure)[c(2,5,1,4,3)]
read_cateogry_order <- c("total_sequences", "Mapped_reads", "Uniquely_mapped_non_duplicate_read_count", "MEND") # unique(this_sample_plot_data$read_category)[c(2,1,4,3)]
this_sample_plot_data$read_measure = factor(this_sample_plot_data$read_measure , levels=read_measure_order)
this_sample_plot_data$read_category = factor(this_sample_plot_data$read_category , levels=read_cateogry_order)
ggplot(this_sample_plot_data) + geom_bar(aes(x=read_category , y=read_count/1e6, fill=read_measure),
stat = "identity", pos="stack") +
facet_wrap(~read_category, nrow=1, scale="free_x") +
scale_fill_brewer(palette = "Set1") +
theme(axis.text.x = element_blank()) +
theme(strip.background = element_blank(), strip.text = element_blank())
subset(read_counts_with_limits, sample_id == s) %>% select(read_type, min_pct, max_pct, within_limits, percent_of_total)
}
if (f_run_qc) {
# with random seed 2, it looks like all the fail samples have lower total sequence depth
# In fact, passing samples have the lowest median total sequences count
read_counts_with_limits %>% select(total_sequences, sample_id, failed_thresholds) %>%
group_by(failed_thresholds) %>%
summarize(median_total_seq_count = median(total_sequences),
mean_total_seq_count = mean(total_sequences)
) %>%
arrange(desc(median_total_seq_count))
ggplot(read_counts_with_limits)   + geom_histogram(aes(total_sequences)) + facet_wrap(~failed_thresholds)
}
if (f_run_qc) {
read_counts_with_percentages_20U <- read_counts_with_percentages %>%
group_by(sample_id) %>%
dplyr::filter(
read_countM[read_type == "MEND"] > 20,
!read_type == "Multi-mapped")
read_type_names <- better_names_for_read_types
names(read_type_names)= names(category_colors)
read_type_labeller <- function(variable,value){
return(read_type_names[value])
}
dupe_frac_compare <- read_counts_with_percentages_20U %>%
filter(read_type=="Duplicate reads") %>%
mutate(depth_category = round(total_sequences/10E6))
# p20 <-
ggplot(dupe_frac_compare) +
geom_histogram(aes(x = percent_of_total, fill = read_type)) +
geom_vline(data = subset(read_type_mean_and_sd_20U, read_type=="Duplicate reads"),
aes(xintercept = value,
color = read_type,
linetype = stat2)) +
scale_fill_manual(values = category_colors) +
scale_color_manual(values = category_colors) +
facet_wrap(~depth_category)
ggplot(dupe_frac_compare) + geom_point(aes(x=total_sequences, y=Percent_duplicates, color=pct_MEND * total_sequences >40E6))
}
read_counts_with_limits
# Why do they fail?
fail_analysis <- read_counts_with_limits %>% select(sample_id, failed_thresholds) %>% distinct
fail_analysis
table(fail_analysis$failed_thresholds)
sort(table(fail_analysis$failed_thresholds))
fail_analysis %>%
mutate(fail_code = strplit(failed_thresholds, ", ")) %>%
unnest(fail_code)
fail_analysis %>%
mutate(fail_code = strsplit(failed_thresholds, ", ")) %>%
unnest(fail_code)
fail_analysis %>%
mutate(fail_code = strsplit(failed_thresholds, ", ")) %>%
unnest(fail_code) %>%
select(-failed_thresholds) %>%
tabyl(fail_code)
fail_analysis %>%
mutate(fail_code = strsplit(failed_thresholds, ", ")) %>%
unnest(fail_code) %>%
select(-failed_thresholds) %>%
tabyl(fail_code) %>%
as_tibble
fail_analysis %>%
mutate(fail_code = strsplit(failed_thresholds, ", ")) %>%
unnest(fail_code) %>%
select(-failed_thresholds) %>%
tabyl(fail_code) %>%
as_tibble %>%
arrange(percent)
long_fail_status <- fail_analysis %>%
mutate(fail_code = strsplit(failed_thresholds, ", ")) %>%
unnest(fail_code) %>%
select(-failed_thresholds)
long_fail_status
long_fail_status %>%
spread(fail_code, "TRUE")
?spread
long_fail_status %>%
mutate(present = TRUE) %>%
spread(fail_code, present)
long_fail_status %>%
mutate(present = TRUE) %>%
spread(fail_code, present, fill = FALSE)
wide_fail_status <- long_fail_status %>%
mutate(present = TRUE) %>%
spread(fail_code, present, fill = FALSE)
wide_fail_status
ggplot(long_fail_status %>% mutate(present = TRUE)) +
geom_tile(aes(x=sample_id, y=fail_code, fill = present))
wide_fail_status
long_fail_status
wide_fail_status
ggplot(long_fail_status %>% mutate(present = TRUE)) +
geom_tile(aes(x=sample_id, y=fail_code, fill = present))
read_counts_with_limits %>% select(sample_id, status) %>% distinct %>% pull(status) %>% table
long_fail_status %>%
tabyl(fail_code) %>%
as_tibble %>%
arrange(percent)
690/1088
read_counts_with_limits %>% select(sample_id, status) %>% distinct %>% pull(status) %>% table
fail_analysis <- read_counts_with_limits %>% select(sample_id, failed_thresholds) %>% distinct
sort(table(fail_analysis$failed_thresholds))
long_fail_status <- fail_analysis %>%
mutate(fail_code = strsplit(failed_thresholds, ", ")) %>%
unnest(fail_code) %>%
select(-failed_thresholds)
long_fail_status %>%
tabyl(fail_code) %>%
as_tibble %>%
arrange(percent)
wide_fail_status <- long_fail_status %>%
mutate(present = TRUE) %>%
spread(fail_code, present, fill = FALSE)
ggplot(long_fail_status %>% mutate(present = TRUE)) +
geom_tile(aes(x=sample_id, y=fail_code, fill = present))
fail_analysis %>%
tabyl(failed_thresholds)
fail_analysis %>%
tabyl(failed_thresholds) %>%
arrange(n)
fail_analysis %>%
tabyl(failed_thresholds) %>%
arrange(desc(n))
long_fail_status %>%
tabyl(fail_code) %>%
arrange(percent)
long_fail_status
long_fail_status %>%
filter (fail_code != "MM") %>%
pull(sample_id) %>%
unique %>%
length
long_fail_status %>%
pull(sample_id) %>%
unique %>%
length
long_fail_status %>%
filter (fail_code != "MM") %>%
pull(sample_id) %>%
unique %>%
length
table(read_counts_with_limits$read_type)
# what does multi-mapper distribution look like?
read_counts_with_limits %>% filter(read_type == "Multi-mapped")
# what does multi-mapper distribution look like?
read_counts_with_limits %>% filter(read_type == "Multi-mapped") %>%
ggplot + geom_boxplot(aes(y=percent_of_total, x=read_type))
wide_fail_status
wide_fail_status %>%
select(-sample_id) %>%
colSums
# how many fail codes
wide_fail_status %>%
select(-sample_id) %>%
rowSums
# how many fail codes
wide_fail_status %>%
select(-sample_id) %>%
mutate(n_fails = rowSums)
# how many fail codes
wide_fail_status %>%
select(-sample_id) %>%
mutate(n_fails = rowSums())
# how many fail codes
wide_fail_status %>%
select(-sample_id) %>%
mutate(n_fails = rowSums(.))
# how many fail codes
fails_per_sample <- wide_fail_status %>%
select(-sample_id) %>%
mutate(n_fails = rowSums(.))
tabyl(fails_per_sample, n_fails)
# most failing samples exceeded the reference ranges of more than one type of read.
table(fails_per_sample$n_fails>1)
gene_of_interest_hugo <-  params$gene_of_interest_hugo
sample_of_interest <-  params$sample_of_interest
print(gene_of_interest_hugo)
print(sample_of_interest)
library(tidyverse)
# library(biomaRt)
library(Sushi)
library(knitr)
f_RMD <- isTRUE(getOption('knitr.in.progress'))
ens_hugo_conversions <- read_tsv("EnsGeneID_Hugo_Observed_Conversions.txt") %>%  na.omit
gene_of_interest_ensembl <- ens_hugo_conversions$EnsGeneID[
ens_hugo_conversions$HugoID == gene_of_interest_hugo]
iso_results <- read_tsv("rsem_isoforms.results")
this_gene_iso_results <- iso_results %>% filter(gene_id == gene_of_interest_ensembl)
gtf_colnames <- c("seqname", "source", "feature", "start", "end", "score", "strand", "frame", "attribute")
# gtf <- "gencode.v23.annotation.gtf.gz"
gtf <- "Treehouse_druggable_gencode.v23.annotation.gtf.gz"
gencode_v23 <- read_tsv(gtf, comment = "#", col_names = gtf_colnames)
gencode_v23_this_gene <- gencode_v23 %>%
filter(grepl(gene_of_interest_ensembl, attribute))  %>%
mutate(gene_id = gsub("\".*$", "",
gsub("^gene_id \"", "\\1", attribute)),
transcript_id = gsub("^.*transcript_id \"([A-Z0-9\\.]*)\".*$",
"\\1", attribute),
feature_length = end - start
)
gencode_v23_this_gene_transcripts <- gencode_v23_this_gene %>%
filter(feature == "transcript")
KVsep <- fixed("; ")  #key-value separator
Vsep <- fixed(" ")     #value separator
gencode_v23_this_gene_transcript_minutia <-  gencode_v23_this_gene_transcripts %>%
mutate(KVpairs = str_split(attribute, KVsep)) %>%
unnest(KVpairs) %>%
separate(KVpairs, into = c("key", "value"), Vsep) %>%
filter( !(key == "tag" & value !="basic"))  %>% # keep tag only if basic
mutate(value = gsub("\"", "", value)) %>%
spread(key, value)
this_gene_iso_results_anno <- this_gene_iso_results %>%
left_join(gencode_v23_this_gene_transcript_minutia %>%
dplyr::select (-gene_id),
by="transcript_id") %>%
mutate(transcript_id = fct_reorder(transcript_id, IsoPct))
# table(this_gene_iso_results_anno$transcript_type)
n_transcripts_to_analyze <- 10
top_iso_results_anno <- this_gene_iso_results_anno %>%
top_n(n_transcripts_to_analyze, IsoPct)
ggplot(top_iso_results_anno %>% filter(TPM > 0)) +
geom_rect(aes(xmin=0, xmax=length, ymin=0,
ymax = TPM, fill = transcript_type)) +
facet_wrap(~transcript_id, ncol = 1, strip.position="right")  +
theme(strip.text.y = element_text(angle = 0)) +
scale_fill_brewer(palette = "Set1") +
xlab("Transcript length") +
ylab("Expression (log2(TPM+1))") +
ggtitle(paste("Relative expression of isoforms of", gene_of_interest_hugo, "in",
sample_of_interest))
exon_locations <- gencode_v23_this_gene %>%
filter(feature %in% c("exon", "UTR")) %>%
left_join(top_iso_results_anno %>%
dplyr::select(transcript_id, IsoPct, TPM, transcript_type, transcript_name),
by=c("transcript_id")) %>%
mutate(score = IsoPct,
transcript_label = paste0(transcript_name, " (",
IsoPct, "%, ", transcript_type, ")"),
# transcript_label = ifelse(transcript_id ==
#                             longest_protein_coding_transcript,
#                           paste(transcript_label, "-canonical"),
#                           transcript_label)
) %>%
dplyr::select(chrom = seqname, start, stop = end,
gene = transcript_id, score,
strand, type = feature, IsoPct, TPM, transcript_label, transcript_name) %>%
arrange(desc(IsoPct))
plot_gene <- function(submitted_bed_data, buffer_size = 5e2, plot_title = ""){
bed_data = data.frame(submitted_bed_data)
chrom <- bed_data$chrom[1]
chromstart = min(bed_data$start) - buffer_size
chromend = max(bed_data$stop) + buffer_size
pg = plotGenes(bed_data,chrom,chromstart,chromend,
#colorby=log10(bed_data$score+0.001),
colorby=bed_data$score,
#colorbycol= SushiColors(5),colorbyrange=c(0,1.0),
labeltext=TRUE,maxrows=50,height=0.4,plotgenetype="box",
packrow = FALSE
)
labelgenome( chrom, chromstart,chromend,n=3,scale="Mb")
# note: add legend has to be hand-placed for each plot, so I've omitted it here
title(main = plot_title, sub = "Colored by isoform percent, also reported in label")
}
# Ellen's summary of our plan:
# E: your code generates PDF and this full res image. The wrapper that i
#    have to write anyhow will downscale the image in python and throw
#    away the giant png and then we embed that in the html
# Plot all transcripts (commented out for production)
# exon_locations %>% mutate(gene = transcript_label) %>% plot_gene
expressed_transcripts <- exon_locations %>%
mutate(gene = transcript_label) %>%
dplyr::filter(TPM > 0)
this_title <- paste("Expressed", gene_of_interest_hugo, "isoforms")
base_filename <- gsub(" ", "_", this_title)
## If using RMD to generate html output, make plot
if( f_RMD ) plot_gene (expressed_transcripts, plot_title = this_title)
## If scripted, make plots in output files
if( ! f_RMD ) {
## Make PDF (small file size, can be endlessly enlarged, inconvenient to embed in html)
pdf(file = paste0(base_filename, ".pdf"),
width = 8, height = 4)
plot_gene (expressed_transcripts, plot_title = this_title)
dev.off()
## Make high res PNG (large file size, convenient to embed in html)
png(file = paste0(base_filename, ".png"),
width = 12, height = 6, units = "in", res = 600)
plot_gene (expressed_transcripts, plot_title = this_title)
dev.off()
}
# create a treemap with tile labels
library(treemapify)
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(RColorBrewer)
library(knitr)
library(forcats)
library(cowplot)
library(gridExtra)
library(jsonlite)
library(janitor)
# /Users/hbeale/Documents/Dropbox/ucsc/projects/seqGroomer/TreehouseIndex19Jun2-HboriginalInputFileL_DATA_2019-06-27_2059.csv
mi_pattern <- "^.* (.*) .*$"
raw_author_info <- read_tsv("Beale-QC-affiliations.tsv") %>%
dplyr::select(full_name = Author, email = `Email address`) %>%
mutate(last_name = gsub("^.* ", "", full_name),
first_name = gsub(" .*$", "", full_name),
middle_name_or_initial = ifelse (grepl(mi_pattern, full_name), gsub("\\.$", "", gsub(mi_pattern, "\\1", full_name)), ""),
first_initial = substr(first_name,1, 1),
middle_initial = substr(middle_name_or_initial,1, 1)
)
cat(raw_author_info$full_name, sep=", ")
raw_author_info %>%
mutate(janAbsName = paste0(last_name,", ", first_initial, ".") ) %>%
pull(janAbsName) %>% cat(sep=", ")
cat(raw_author_info$full_name, sep=", ")
extra_aacr <- read_tsv("AACR QC abstract author info.tsv")
raw_author_info
extra_aacr
extra_aacr <- read_tsv("AACR QC abstract author info.tsv") %>%
rename(email = `Email address`, degree = `Degree/Education Status`)
extra_aacr <- read_tsv("AACR QC abstract author info.tsv") %>%
rename(email = `Email address`, degree = `Degree/Education Status: `)
extra_aacr <- read_tsv("AACR QC abstract author info.tsv") %>%
rename(email = `Email address`, degree = `Degree/Education Status:`)
raw_author_info
extra_aacr <- read_tsv("AACR QC abstract author info.tsv") %>%
rename(email = `Email address`, degree = `Degree/Education Status:`) %>%
select(-Author)
