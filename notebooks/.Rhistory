read_counts_with_outlier_anno <- read_counts_with_percentages %>%
mutate(
total_seq_up_outlier = total_sequences > outlier_thresholds_for_depth["up"],
total_seq_down_outlier = total_sequences < outlier_thresholds_for_depth["down"]
)
table(read_counts_with_outlier_anno$total_seq_down_outlier)
table(read_counts_with_outlier_anno$total_seq_up_outlier)
read_counts_without_total_seq_outliers <- read_counts_with_outlier_anno %>%
filter(!total_seq_down_outlier,
!total_seq_up_outlier)
print(paste("exclude", length(unique(read_counts_with_percentages$sample_id)) - length(unique(read_counts_without_total_seq_outliers$sample_id)), "samples that were outliers with respect to sequence depth"))
read_type_training_set <- read_counts_without_total_seq_outliers %>%
group_by(sample_id) %>%
dplyr::filter(read_countM[read_type == "UMEND"] > 20)
read_type_mean_and_sd_20U <- read_type_training_set %>%
group_by(read_type) %>%
summarize(mean_pct_of_total = mean(percent_of_total),
one_sd = sd(percent_of_total),
mean_minus_one_sd = mean_pct_of_total - one_sd,
mean_plus_one_sd = mean_pct_of_total + one_sd,
mean_minus_two_sd = mean_pct_of_total - one_sd * 2,
mean_plus_two_sd = mean_pct_of_total + one_sd * 2) %>%
gather(stat, value, -one_sd, -read_type) %>%
mutate(stat2 = gsub("^.*two_sd", "two_sd", gsub("^.*one_sd", "one_sd", stat)))
# read_types_with_a_lower_bound <- c("UMEND", "Duplicate reads", "Multi-mapped")
read_types_with_a_lower_bound <- unique(read_type_mean_and_sd_20U$read_type)
read_type_pct_thresholds_raw <- read_type_mean_and_sd_20U %>%
dplyr::filter(grepl("two_sd", stat)) %>%
mutate(value2 = ifelse(grepl("minus_two_sd", stat),
ifelse(read_type %in% read_types_with_a_lower_bound,
value,
0),
value))
#
# read_type_pct_thresholds <- read_type_pct_thresholds_raw %>%
#  select(read_type, stat, value2) %>%
#   spread(stat, value2) %>%
#   rename(min_pct = mean_minus_two_sd, max_pct = mean_plus_two_sd)
read_type_pct_thresholds <- read_type_pct_thresholds_raw %>%
select(read_type, stat, value) %>%
spread(stat, value) %>%
rename(min_pct = mean_minus_two_sd, max_pct = mean_plus_two_sd)
read_counts_with_thresholds <- left_join(read_counts_with_percentages, read_type_pct_thresholds, by = "read_type") %>%
mutate(within_limits = ifelse(percent_of_total > min_pct,
ifelse(percent_of_total<max_pct,
"within_limits",
"above_limit"),
"below_limit"))
samples_within_limits <- read_counts_with_thresholds %>%
group_by(sample_id) %>%
filter(sum(grepl("within_limits", within_limits)) == length(unique(read_counts_with_thresholds$read_type))) %>%
pull(sample_id) %>% unique
depth_status <- read_counts_with_slices %>%
select(sample_id, UMEND) %>%
mutate(
status=ifelse( UMEND<10E6,
"<10M_UMEND_reads",
ifelse(UMEND<20E6,
"10-20 UMEND_reads",
">20M_UMEND_reads")
),
all_read_types_within_read_type_limits = sample_id %in% samples_within_limits,
within_read_type_limits_label = c( "not_WNL", "WNL")[1 + all_read_types_within_read_type_limits]
)
tabyl(depth_status, within_read_type_limits_label, status)
threshold_codes=c("NM"="Not mapped", "MM"="Multi-mapped", "D"="Duplicate reads", "NE" = "Non exonic reads", "U" = "UMEND")
threshold_failure_annotations <- read_counts_with_thresholds %>%
mutate(threshold_code = ifelse(within_limits == "within_limits", NA, names(threshold_codes)[match(read_type, threshold_codes)])) %>%
group_by(sample_id, total_sequences) %>%
summarize(failed_thresholds = paste(na.omit(threshold_code), collapse=", "))
read_counts_with_limits <- read_counts_with_thresholds %>%
left_join(depth_status, by="sample_id") %>%
left_join(threshold_failure_annotations %>% select(-total_sequences), by="sample_id")
# smaller dataset to show individual samples
# 861 samples in this size range
reasonably_sized_samples <- read_counts_with_limits %>%
select(sample_id, total_sequences) %>%
distinct %>%
filter(total_sequences < 150E6) %>% # the most relevant set, and limiting makes plots intelligible
pull(sample_id)
# read_counts_with_limits %>% filter(sample_id %in% reasonably_sized_samples) %>% pull(total_sequences) %>% range
# What features does the dataset need to have?
# distribution_in_full_dataset_raw <- rev(sort(table(subset(threshold_failure_annotations, sample_id %in% reasonably_sized_samples)$failed_thresholds)))
distribution_in_full_dataset_raw <- rev(sort(table(threshold_failure_annotations$failed_thresholds)))
# error_distribution <- tibble(error_group_name = gsub("^$", "Pass", names(distribution_in_full_dataset_raw)),
error_distribution <- tibble(error_group_name =names(distribution_in_full_dataset_raw),
freq_in_full_dataset = as.numeric(distribution_in_full_dataset_raw),
desired_freq_in_subset=freq_in_full_dataset*n_samples_to_plot/nrow(threshold_failure_annotations),
desired_freq_in_subset_integer=round(desired_freq_in_subset),
curated_target_freq_in_subset = desired_freq_in_subset_integer
)
# if rounded fractions don't add to 50, fill
while (sum(error_distribution$curated_target_freq_in_subset)<n_samples_to_plot){
row_for_passing_samples <- which(error_distribution$error_group_name  %in%  "")[1]
error_distribution$curated_target_freq_in_subset[row_for_passing_samples] = error_distribution$curated_target_freq_in_subset[row_for_passing_samples] + 1
}
# sum(error_distribution$curated_target_freq_in_subset)
random_samples <- apply(error_distribution, 1, function(x){
# x=error_distribution[2,]
n_to_sample = round(as.numeric(x["curated_target_freq_in_subset"]))
threshold_code = as.character(x["error_group_name"])
if (threshold_code=="Pass") threshold_code = ""
if (n_to_sample >0){
set.seed(3)
subset(read_counts_with_limits, sample_id %in% reasonably_sized_samples & failed_thresholds == threshold_code) %>%
select(sample_id) %>%
sample_n(n_to_sample)
}
}
) %>% bind_rows %>% pull(sample_id)
# read_counts_with_limits %>% filter(sample_id %in% random_samples) %>% pull(total_sequences) %>% range
selected_parent_samples <- tibble(THid = parent_sample_data$`Treehouse ID`)
# selected_parent_samples$plot_id = paste0("S", 1:nrow(selected_parent_samples))
selected_parent_samples$plot_id = "*"
set.seed(2)
# random_samples <- read_counts_from_reasonably_sized_samples[sample(1:n_random_samples_needed,n_samples_to_plot),]$sample_id
samples_for_small_dataset <- c(selected_parent_samples$THid, random_samples)
# special_designation=c("other", "From_Fig1")
# special_designation <- c("", "*")
# small_plot_data <- subset(read_counts_with_percentages, sample_id %in% samples_for_small_dataset) %>%
small_plot_data <- subset(read_counts_with_limits, sample_id %in% samples_for_small_dataset) %>%
mutate(
highlight_text = selected_parent_samples$plot_id[match(sample_id, selected_parent_samples$THid)],
sample_id = factor(sample_id, levels=samples_in_depth_order[samples_in_depth_order %in% sample_id])
)
# small_plot_data$highlight_text = factor(special_designation[1 + small_plot_data$sample_id %in% example_samples_to_force_into_small_dataset],
#                                        levels = rev(special_designation))
# selected_small_plot_data <- read_counts_with_percentages %>%
selected_small_plot_data <- read_counts_with_limits %>%
dplyr::filter(sample_id %in% selected_parent_samples$THid)
#table(small_plot_data$read_type
#     )
# cat(small_plot_data %>% pull(sample_id) %>% unique %>% as.character, file="../data/samples_to_plot.txt")
small_plot_data$not_WNL <- ! small_plot_data$sample_id  %in% samples_within_limits
# includes all samples
min_UMEND = 20 * 1e6
adjusted_read_counts <- read_counts_with_limits %>%
filter(read_type !="Multi-mapped") %>%
group_by(sample_id) %>%
mutate(adjustment_factor = 1 / (read_count[read_type == "UMEND"]/min_UMEND),
adjust_read_count = adjustment_factor * read_count,
total_adjusted_read_count = sum(adjust_read_count))
# includes only samples within the reference ranges
proposed_thresholds = c(1,seq(4,48, by = 4))
percentiles_to_query = 0.95 # c(50, 75, 95, 100)/100
#library(purrr)
# remove failed samples
read_counts_within_limits <- read_counts_with_limits %>%
filter(sample_id %in% samples_within_limits)
proposed_threshold=1
percentile_to_query=0.95
rescale_and_get_percentile <- function(proposed_threshold, percentile_to_query) {
read_counts_within_limits %>%
filter(read_type == "UMEND") %>%
mutate(adjustment_factor = 1 / (read_count / (proposed_threshold * 1e6)),
adjusted_total = adjustment_factor * total_sequences) %>%
pull(adjusted_total) %>%
quantile(percentile_to_query)
}
predictions <- NULL
for (proposed_threshold in proposed_thresholds) {
for (percentile_to_query in percentiles_to_query){
predictions <- bind_rows(predictions,
tibble(proposed_threshold,
percentile_to_query,
predicted_total_reads = rescale_and_get_percentile(proposed_threshold,
percentile_to_query)))
}
}
write_tsv(predictions %>% filter(percentile_to_query==0.95),
"../data/predicted_required_total_reads_within_limits.tsv")
plot_title <- "Total number of reads in a sample does not predict the number of UMEND reads"
figure_name <- "read_count_and_fractions_figures_v2"
small_plot_data_no_MM <- subset(small_plot_data, !read_type == "Multi-mapped")
# note negative values in small_plot_data$read_countM, e.g. -0.4817530
p1 <- ggplot(small_plot_data_no_MM) +
geom_bar(data = small_plot_data_no_MM,
aes(x = sample_id,
y = read_countM,
fill = read_type),
size = 1,
stat = "identity") +
scale_fill_manual("Read type", values = category_colors, labels=better_names_for_read_types) +
scale_color_grey(end = 0.6) +
# facet_grid(.~highlight_sample, scales="free_x", space="free") +
xlab(paste0("Samples, n=", length(samples_for_small_dataset))) +
ylab("Read count (millions)") +
#  ylim(0, 175) +
geom_text(data=subset(small_plot_data_no_MM, read_type == "UMEND"),
aes(x = sample_id,
y = 1 + total_sequences / 1e6,
label = highlight_text),
color = "black",
size = 5) +
geom_text(data=subset(threshold_failure_annotations, sample_id %in% small_plot_data_no_MM$sample_id),
aes(x = sample_id,
y = 1 + total_sequences / 1e6,
label = failed_thresholds),
angle=90, hjust=0,
color = "darkred",
size=3) +
# labs(caption= paste(figure_name, Sys.time())) +
theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
#           legend.position = c(.4,.86)
legend.position = c(0.65, 0.8)
#   plot.caption = element_text(hjust = -1)
)
#geom_text(data=selected_small_plot_data, aes(x=sample_id, y=total_sequences), label="*")
p1
dim(subset(threshold_failure_annotations, sample_id %in% small_plot_data_no_MM$sample_id))
table(small_plot_data_no_MM$read_type)
category_colors
category_colors
knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_knit$set(root.dir = "~/Documents/Dropbox/ucsc/projects/gitCode/drafts_of_umend_qc_publication/")
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(gridGraphics)
library(RColorBrewer)
library(viridis)
library(ggrepel)
library(cowplot)
library(janitor)
n_samples_to_plot <- 50
f_run_qc <- FALSE
f_label_bars_in_55_sample_plot <- FALSE
library(RColorBrewer)
source_palette <- brewer.pal(12, "Paired")
cb_dark_green <- source_palette[4]
cb_light_green <- source_palette[3]
raw_names_for_read_types_mm <-  c("not_mapped", "Multimapped_read_count", "duplicate_reads", "non_exonic_reads", "UMEND")
intermediate_names_for_read_types_mm = c("Not mapped", "Multi-mapped", "Duplicate reads", "Non exonic reads", "UMEND")
better_names_for_read_types_mm <- c("Not mapped", "Multi-mapped", "Duplicate", "Non exonic", "UMEND")
raw_names_for_read_types <-  c("not_mapped",  "duplicate_reads", "non_exonic_reads", "UMEND")
intermediate_names_for_read_types = c("Not mapped", "Duplicate reads", "Non exonic reads", "UMEND")
better_names_for_read_types <- c("Not mapped",  "Duplicate", "Non exonic", "UMEND")
category_colors <- c(grey(0.5),  cb_light_green, grey(0.7), cb_dark_green)
names(category_colors) <- intermediate_names_for_read_types
category_colors_mm <- c(grey(0.5), "blue", cb_light_green, grey(0.7), cb_dark_green)
names(category_colors_mm) <- intermediate_names_for_read_types
multimapper_colors <- c(source_palette[6], source_palette[2] )
names(multimapper_colors) <- c("Multi-mapped", "Uniquely mapped")
allCountsRaw <- read_tsv(file.path( "../data/raw_read_survey_results_2019_05_13.txt"),
col_names = c("sample_id", "count_type", "read_count")) %>%
spread(count_type, read_count)
samples_in_depth_order = allCountsRaw$sample_id[order(desc(allCountsRaw$total_sequences))]
parent_sample_data <- read_tsv("../data/parent_sample_data_source.tsv") %>% rename(pub_ID = publication_id)
complete_counts_raw <- na.omit(allCountsRaw) %>%
filter(!grepl("TH06", sample_id)) # exclude placeholder QC values from TH06 (we don't have real QC values for these samples)
complete_counts <- complete_counts_raw %>%
mutate(Mapped_read_count = Multimapped_read_count + Uniquely_mapped_read_count) %>%
select(-Uniquely_mapped_read_count)
# consider excluding samples in which duplicates may have been removed
# dplyr::filter(!grepl("THR08", sample_id )) # i think duplicates may have been removed from these samples
# nrow (filter(allCountsRaw, grepl("THR08", sample_id )))
# effect of excluding NA, which are usually samples without four measurements
nrow(na.omit(complete_counts))
nrow((complete_counts))
read_counts <- complete_counts %>%
rename(UM = Mapped_read_count,
UMND = Uniquely_mapped_non_duplicate_read_count)
orderByTotalReads <- read_counts %>% arrange(desc(total_sequences)) %>%	.$sample_id
read_counts_with_slices <- read_counts %>%
arrange(desc(total_sequences)) %>%
mutate(pct_UMEND = UMEND / total_sequences,
Percent_duplicates = 1 - (UMND / UM),
not_mapped = total_sequences - UM,
duplicate_reads = UM - UMND,
non_exonic_reads = UMND - UMEND,
sum_slices = UMEND + non_exonic_reads + duplicate_reads + not_mapped)
read_counts_with_percentages <- read_counts_with_slices %>%
select(sample_id,
not_mapped,
duplicate_reads,
non_exonic_reads,
UMEND,
Multimapped_read_count,
UM,
Percent_duplicates,
pct_UMEND,
total_sequences) %>%
gather(read_type, read_count, not_mapped, duplicate_reads, non_exonic_reads, UMEND, Multimapped_read_count) %>%
mutate(read_type = intermediate_names_for_read_types_mm[match(read_type, raw_names_for_read_types_mm)],
read_type = factor(read_type,
levels = intermediate_names_for_read_types_mm),
sample_id = factor(sample_id, levels = orderByTotalReads),
read_countM = read_count / 1e6,
divisor_for_percent = ifelse(read_type=="Multi-mapped", UM, total_sequences),
percent_of_total = read_count / divisor_for_percent)
calculate_outliers_thresholds <- function(x, IQR_multFactor=1.5) {
theseQuartiles=quantile(x, c(1/4,3/4), names=FALSE)
IQR =theseQuartiles[2]-theseQuartiles[1]
up_outlier_threshold = theseQuartiles[2] + (IQR_multFactor * IQR)
down_outlier_threshold = theseQuartiles[1] - (IQR_multFactor * IQR)
return(c("down" = down_outlier_threshold, "up" = up_outlier_threshold))
}
outlier_thresholds_for_depth = calculate_outliers_thresholds(read_counts_with_percentages$total_sequences)
# depth_outliers # down outlier threshold is negative; no samples have negative
read_counts_with_outlier_anno <- read_counts_with_percentages %>%
mutate(
total_seq_up_outlier = total_sequences > outlier_thresholds_for_depth["up"],
total_seq_down_outlier = total_sequences < outlier_thresholds_for_depth["down"]
)
table(read_counts_with_outlier_anno$total_seq_down_outlier)
table(read_counts_with_outlier_anno$total_seq_up_outlier)
read_counts_without_total_seq_outliers <- read_counts_with_outlier_anno %>%
filter(!total_seq_down_outlier,
!total_seq_up_outlier)
print(paste("exclude", length(unique(read_counts_with_percentages$sample_id)) - length(unique(read_counts_without_total_seq_outliers$sample_id)), "samples that were outliers with respect to sequence depth"))
read_type_training_set <- read_counts_without_total_seq_outliers %>%
group_by(sample_id) %>%
dplyr::filter(read_countM[read_type == "UMEND"] > 20)
read_type_mean_and_sd_20U <- read_type_training_set %>%
group_by(read_type) %>%
summarize(mean_pct_of_total = mean(percent_of_total),
one_sd = sd(percent_of_total),
mean_minus_one_sd = mean_pct_of_total - one_sd,
mean_plus_one_sd = mean_pct_of_total + one_sd,
mean_minus_two_sd = mean_pct_of_total - one_sd * 2,
mean_plus_two_sd = mean_pct_of_total + one_sd * 2) %>%
gather(stat, value, -one_sd, -read_type) %>%
mutate(stat2 = gsub("^.*two_sd", "two_sd", gsub("^.*one_sd", "one_sd", stat)))
# read_types_with_a_lower_bound <- c("UMEND", "Duplicate reads", "Multi-mapped")
read_types_with_a_lower_bound <- unique(read_type_mean_and_sd_20U$read_type)
read_type_pct_thresholds_raw <- read_type_mean_and_sd_20U %>%
dplyr::filter(grepl("two_sd", stat)) %>%
mutate(value2 = ifelse(grepl("minus_two_sd", stat),
ifelse(read_type %in% read_types_with_a_lower_bound,
value,
0),
value))
#
# read_type_pct_thresholds <- read_type_pct_thresholds_raw %>%
#  select(read_type, stat, value2) %>%
#   spread(stat, value2) %>%
#   rename(min_pct = mean_minus_two_sd, max_pct = mean_plus_two_sd)
read_type_pct_thresholds <- read_type_pct_thresholds_raw %>%
select(read_type, stat, value) %>%
spread(stat, value) %>%
rename(min_pct = mean_minus_two_sd, max_pct = mean_plus_two_sd)
read_counts_with_thresholds <- left_join(read_counts_with_percentages, read_type_pct_thresholds, by = "read_type") %>%
mutate(within_limits = ifelse(percent_of_total > min_pct,
ifelse(percent_of_total<max_pct,
"within_limits",
"above_limit"),
"below_limit"))
samples_within_limits <- read_counts_with_thresholds %>%
group_by(sample_id) %>%
filter(sum(grepl("within_limits", within_limits)) == length(unique(read_counts_with_thresholds$read_type))) %>%
pull(sample_id) %>% unique
depth_status <- read_counts_with_slices %>%
select(sample_id, UMEND) %>%
mutate(
status=ifelse( UMEND<10E6,
"<10M_UMEND_reads",
ifelse(UMEND<20E6,
"10-20 UMEND_reads",
">20M_UMEND_reads")
),
all_read_types_within_read_type_limits = sample_id %in% samples_within_limits,
within_read_type_limits_label = c( "not_WNL", "WNL")[1 + all_read_types_within_read_type_limits]
)
tabyl(depth_status, within_read_type_limits_label, status)
threshold_codes=c("NM"="Not mapped", "MM"="Multi-mapped", "D"="Duplicate reads", "NE" = "Non exonic reads", "U" = "UMEND")
threshold_failure_annotations <- read_counts_with_thresholds %>%
mutate(threshold_code = ifelse(within_limits == "within_limits", NA, names(threshold_codes)[match(read_type, threshold_codes)])) %>%
group_by(sample_id, total_sequences) %>%
summarize(failed_thresholds = paste(na.omit(threshold_code), collapse=", "))
read_counts_with_limits <- read_counts_with_thresholds %>%
left_join(depth_status, by="sample_id") %>%
left_join(threshold_failure_annotations %>% select(-total_sequences), by="sample_id")
# smaller dataset to show individual samples
# 861 samples in this size range
reasonably_sized_samples <- read_counts_with_limits %>%
select(sample_id, total_sequences) %>%
distinct %>%
filter(total_sequences < 150E6) %>% # the most relevant set, and limiting makes plots intelligible
pull(sample_id)
# read_counts_with_limits %>% filter(sample_id %in% reasonably_sized_samples) %>% pull(total_sequences) %>% range
# What features does the dataset need to have?
# distribution_in_full_dataset_raw <- rev(sort(table(subset(threshold_failure_annotations, sample_id %in% reasonably_sized_samples)$failed_thresholds)))
distribution_in_full_dataset_raw <- rev(sort(table(threshold_failure_annotations$failed_thresholds)))
# error_distribution <- tibble(error_group_name = gsub("^$", "Pass", names(distribution_in_full_dataset_raw)),
error_distribution <- tibble(error_group_name =names(distribution_in_full_dataset_raw),
freq_in_full_dataset = as.numeric(distribution_in_full_dataset_raw),
desired_freq_in_subset=freq_in_full_dataset*n_samples_to_plot/nrow(threshold_failure_annotations),
desired_freq_in_subset_integer=round(desired_freq_in_subset),
curated_target_freq_in_subset = desired_freq_in_subset_integer
)
# if rounded fractions don't add to 50, fill
while (sum(error_distribution$curated_target_freq_in_subset)<n_samples_to_plot){
row_for_passing_samples <- which(error_distribution$error_group_name  %in%  "")[1]
error_distribution$curated_target_freq_in_subset[row_for_passing_samples] = error_distribution$curated_target_freq_in_subset[row_for_passing_samples] + 1
}
# sum(error_distribution$curated_target_freq_in_subset)
random_samples <- apply(error_distribution, 1, function(x){
# x=error_distribution[2,]
n_to_sample = round(as.numeric(x["curated_target_freq_in_subset"]))
threshold_code = as.character(x["error_group_name"])
if (threshold_code=="Pass") threshold_code = ""
if (n_to_sample >0){
set.seed(3)
subset(read_counts_with_limits, sample_id %in% reasonably_sized_samples & failed_thresholds == threshold_code) %>%
select(sample_id) %>%
sample_n(n_to_sample)
}
}
) %>% bind_rows %>% pull(sample_id)
# read_counts_with_limits %>% filter(sample_id %in% random_samples) %>% pull(total_sequences) %>% range
selected_parent_samples <- tibble(THid = parent_sample_data$`Treehouse ID`)
# selected_parent_samples$plot_id = paste0("S", 1:nrow(selected_parent_samples))
selected_parent_samples$plot_id = "*"
set.seed(2)
# random_samples <- read_counts_from_reasonably_sized_samples[sample(1:n_random_samples_needed,n_samples_to_plot),]$sample_id
samples_for_small_dataset <- c(selected_parent_samples$THid, random_samples)
# special_designation=c("other", "From_Fig1")
# special_designation <- c("", "*")
# small_plot_data <- subset(read_counts_with_percentages, sample_id %in% samples_for_small_dataset) %>%
small_plot_data <- subset(read_counts_with_limits, sample_id %in% samples_for_small_dataset) %>%
mutate(
highlight_text = selected_parent_samples$plot_id[match(sample_id, selected_parent_samples$THid)],
sample_id = factor(sample_id, levels=samples_in_depth_order[samples_in_depth_order %in% sample_id])
)
# small_plot_data$highlight_text = factor(special_designation[1 + small_plot_data$sample_id %in% example_samples_to_force_into_small_dataset],
#                                        levels = rev(special_designation))
# selected_small_plot_data <- read_counts_with_percentages %>%
selected_small_plot_data <- read_counts_with_limits %>%
dplyr::filter(sample_id %in% selected_parent_samples$THid)
#table(small_plot_data$read_type
#     )
# cat(small_plot_data %>% pull(sample_id) %>% unique %>% as.character, file="../data/samples_to_plot.txt")
small_plot_data$not_WNL <- ! small_plot_data$sample_id  %in% samples_within_limits
# includes all samples
min_UMEND = 20 * 1e6
adjusted_read_counts <- read_counts_with_limits %>%
filter(read_type !="Multi-mapped") %>%
group_by(sample_id) %>%
mutate(adjustment_factor = 1 / (read_count[read_type == "UMEND"]/min_UMEND),
adjust_read_count = adjustment_factor * read_count,
total_adjusted_read_count = sum(adjust_read_count))
# includes only samples within the reference ranges
proposed_thresholds = c(1,seq(4,48, by = 4))
percentiles_to_query = 0.95 # c(50, 75, 95, 100)/100
#library(purrr)
# remove failed samples
read_counts_within_limits <- read_counts_with_limits %>%
filter(sample_id %in% samples_within_limits)
proposed_threshold=1
percentile_to_query=0.95
rescale_and_get_percentile <- function(proposed_threshold, percentile_to_query) {
read_counts_within_limits %>%
filter(read_type == "UMEND") %>%
mutate(adjustment_factor = 1 / (read_count / (proposed_threshold * 1e6)),
adjusted_total = adjustment_factor * total_sequences) %>%
pull(adjusted_total) %>%
quantile(percentile_to_query)
}
predictions <- NULL
for (proposed_threshold in proposed_thresholds) {
for (percentile_to_query in percentiles_to_query){
predictions <- bind_rows(predictions,
tibble(proposed_threshold,
percentile_to_query,
predicted_total_reads = rescale_and_get_percentile(proposed_threshold,
percentile_to_query)))
}
}
write_tsv(predictions %>% filter(percentile_to_query==0.95),
"../data/predicted_required_total_reads_within_limits.tsv")
plot_title <- "Total number of reads in a sample does not predict the number of UMEND reads"
figure_name <- "read_count_and_fractions_figures_v2"
small_plot_data_no_MM <- subset(small_plot_data, !read_type == "Multi-mapped")
# note negative values in small_plot_data$read_countM, e.g. -0.4817530
p1 <- ggplot(small_plot_data_no_MM) +
geom_bar(data = small_plot_data_no_MM,
aes(x = sample_id,
y = read_countM,
fill = read_type),
size = 1,
stat = "identity") +
scale_fill_manual("Read type", values = category_colors, labels=better_names_for_read_types) +
scale_color_grey(end = 0.6) +
# facet_grid(.~highlight_sample, scales="free_x", space="free") +
xlab(paste0("Samples, n=", length(samples_for_small_dataset))) +
ylab("Read count (millions)") +
#  ylim(0, 175) +
geom_text(data=subset(small_plot_data_no_MM, read_type == "UMEND"),
aes(x = sample_id,
y = 1 + total_sequences / 1e6,
label = highlight_text),
color = "black",
size = 5) +
geom_text(data=subset(threshold_failure_annotations, sample_id %in% small_plot_data_no_MM$sample_id),
aes(x = sample_id,
y = 1 + total_sequences / 1e6,
label = failed_thresholds),
angle=90, hjust=0,
color = "darkred",
size=3) +
# labs(caption= paste(figure_name, Sys.time())) +
theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
#           legend.position = c(.4,.86)
legend.position = c(0.65, 0.8)
#   plot.caption = element_text(hjust = -1)
)
#geom_text(data=selected_small_plot_data, aes(x=sample_id, y=total_sequences), label="*")
p1
dim(subset(threshold_failure_annotations, sample_id %in% small_plot_data_no_MM$sample_id))
