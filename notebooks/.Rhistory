publication_id = unique(pretty_expression$publication_id))) %>%
mutate(
expression_bin_f = factor(as.character(expression_bin), as.character(gene_expression_levels))
)
pretty_expression$expression_bin_f <- factor(as.character(pretty_expression$expression_bin),
levels = as.character(gene_expression_levels))
dummy$expression_bin_f <- factor(as.character(dummy$expression_bin),
levels = as.character(gene_expression_levels))
hline_dummy$expression_bin_f <- factor(hline_dummy$expression_bin_f,
levels = as.character(gene_expression_levels))
ids_to_plot <- c("S1", "S2")
small_pretty_expression <- subset(pretty_expression, publication_id %in% ids_to_plot)
small_hline_dummy <- subset(hline_dummy, publication_id %in% ids_to_plot)
plot_title <- "Range of expression of genes with similar expression"
pBin <- ggplot(small_pretty_expression) +
geom_hline(data = small_hline_dummy, aes(yintercept = expression_bin),
size = 0.25, color = "#6699cc") + # color = "grey") +
geom_boxplot(aes(x = total_reads / 1e6,
y = expression,
group = paste(expression_bin, median_of_depth_bin)), #color=label,
outlier.size = 0.25, width = 3) +
# geom_hline(data=hline_dummy, aes(yintercept=expression_bin), size=0.5, linetype="dotted", color="blue") +
xlab("Total reads (million)") +
ylab("Expression (log2(TPM+1))") +
theme(legend.position = "none") +
facet_grid(expression_bin_f ~ publication_id, scales = "free_y") +
geom_blank(data = dummy, aes(x = total_reads / 1e6, y = expression)) +
scale_y_continuous(breaks = seq(0, 10, by = 2)) +
ggtitle("B")
# ggtitle(plot_title)
pSmallBin2 <- pBin +
background_grid(major = "xy",
minor = "x",
colour.major = "black",
colour.minor = grey(0.75),
size.major = grid_size_major,
size.minor = grid_size_minor) +
theme(axis.line = element_blank(),
plot.title = element_text(hjust = 0)) +
scale_x_continuous(breaks = seq(0, max_x, 25))
pSmallBin2
knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_knit$set(root.dir = "~/Documents/Dropbox/ucsc/projects/gitCode/drafts_of_umend_qc_publication/")
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(gridGraphics)
library(RColorBrewer)
library(viridis)
library(ggrepel)
library(cowplot)
library(janitor)
n_samples_to_plot <- 50
library(RColorBrewer)
source_palette <- brewer.pal(12, "Paired")
cb_dark_green <- source_palette[4]
cb_light_green <- source_palette[3]
raw_names_for_read_types <-  c("not_uniquely_mapped", "duplicate_reads", "non_exonic_reads", "UMEND")
intermediate_names_for_read_types = c("Not uniquely mapped", "Duplicate reads", "Non exonic reads", "UMEND")
better_names_for_read_types <- c("Not uniquely mapped", "Duplicate", "Non exonic", "UMEND")
category_colors <- c(grey(0.5), cb_light_green, grey(0.7), cb_dark_green)
names(category_colors) <- intermediate_names_for_read_types
allCountsRaw <- read_tsv(file.path( "../data/raw_read_survey_results_2019_03_28.txt"),
col_names = c("sample_id", "count_type", "read_count")) %>%
spread(count_type, read_count)
parent_sample_data <- read_tsv("../data/parent_sample_data_source.tsv") %>% rename(pub_ID = publication_id)
complete_counts_raw <- na.omit(allCountsRaw) %>%
filter(!grepl("TH06", sample_id)) # exclude placeholder QC values from TH06 (we don't have real QC values for these samples)
# consider excluding samples in which duplicates may have been removed
# dplyr::filter(!grepl("THR08", sample_id )) # i think duplicates may have been removed from these samples
# nrow (filter(allCountsRaw, grepl("THR08", sample_id )))
# effect of excluding NA, which are usually samples without four measurements
nrow(na.omit(allCountsRaw))
nrow((allCountsRaw))
read_counts <- complete_counts_raw %>%
rename(UM = Uniquely_mapped_read_count,
UMND = Uniquely_mapped_non_duplicate_read_count)
orderByTotalReads <- read_counts %>% arrange(desc(total_sequences)) %>%	.$sample_id
read_counts_with_slices <- read_counts %>%
arrange(desc(total_sequences)) %>%
mutate(pct_UMEND = UMEND / total_sequences,
Percent_duplicates = 1 - (UMND / UM),
not_uniquely_mapped = total_sequences - UM,
duplicate_reads = UM - UMND,
non_exonic_reads = UMND - UMEND,
sum_slices = UMEND + non_exonic_reads + duplicate_reads + not_uniquely_mapped)
plotInfo <- read_counts_with_slices %>%
select(sample_id,
not_uniquely_mapped,
duplicate_reads,
non_exonic_reads,
UMEND,
Percent_duplicates,
pct_UMEND,
total_sequences) %>%
gather(read_type, read_count, not_uniquely_mapped, duplicate_reads, non_exonic_reads, UMEND) %>%
mutate(read_type = intermediate_names_for_read_types[match(read_type, raw_names_for_read_types)],
read_type = factor(read_type,
levels = intermediate_names_for_read_types),
sample_id = factor(sample_id, levels = orderByTotalReads),
read_countM = read_count / 1e6,
percent_of_total = read_count / total_sequences)
# smaller dataset to show individual samples
read_counts_from_reasonably_sized_samples <- read_counts %>%
filter(total_sequences < 150E6) # the most relevant set, and limiting makes plots intelligible
selected_parent_samples <- tibble(THid = parent_sample_data$`Treehouse ID`)
# selected_parent_samples$plot_id = paste0("S", 1:nrow(selected_parent_samples))
selected_parent_samples$plot_id = "*"
n_random_samples_needed <- nrow(read_counts_from_reasonably_sized_samples) - nrow(selected_parent_samples)
set.seed(2)
random_samples <- read_counts_from_reasonably_sized_samples[sample(1:n_random_samples_needed,n_samples_to_plot),]$sample_id
samples_for_small_dataset <- c(selected_parent_samples$THid, random_samples)
# special_designation=c("other", "From_Fig1")
# special_designation <- c("", "*")
small_plot_data <- subset(plotInfo, sample_id %in% samples_for_small_dataset) %>%
mutate(highlight_text = selected_parent_samples$plot_id[match(sample_id, selected_parent_samples$THid)])
# small_plot_data$highlight_text = factor(special_designation[1 + small_plot_data$sample_id %in% example_samples_to_force_into_small_dataset],
#                                        levels = rev(special_designation))
selected_small_plot_data <- plotInfo %>%
dplyr::filter(sample_id %in% selected_parent_samples$THid)
# cat(small_plot_data %>% pull(sample_id), file="../data/samples_to_plot.txt")
small_plot_data
small_plot_data %>% pull(sample_id)
small_plot_data %>% pull(sample_id) %>% unique
small_plot_data %>% pull(sample_id) %>% unique %>% as.charcater
small_plot_data %>% pull(sample_id) %>% unique %>% as.characater
small_plot_data %>% pull(sample_id) %>% unique %>% as.character
cat(small_plot_data %>% pull(sample_id) %>% unique %>% as.character, file="../data/samples_to_plot.txt")
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(gridGraphics)
library(RColorBrewer)
library(viridis)
library(ggrepel)
library(cowplot)
library(forcats)
raw_names_for_read_types <-  c("not_uniquely_mapped", "duplicate_reads", "non_exonic_reads", "UMEND")
intermediate_names_for_read_types = c("Not uniquely mapped", "Duplicate reads", "Non exonic reads", "UMEND")
better_names_for_read_types <- c("Not uniquely mapped", "Duplicate", "Non exonic", "UMEND")
library(RColorBrewer)
source_palette <- brewer.pal(12, "Paired")
cb_dark_green <- source_palette[4]
cb_light_green <- source_palette[3]
category_colors <- c(grey(0.5), cb_light_green, grey(0.7), cb_dark_green)
names(category_colors) <- raw_names_for_read_types
allCountsRaw <- read_tsv(file.path( "raw_read_survey_results_2019_05_10.txt"), col_names = c("sample_id", "count_type", "read_count"))%>%
mutate(count_type = gsub("Uniquely_mapped_read_count", "UM", gsub("Uniquely_mapped_non_duplicate_read_count", "UMND", count_type)))
validCountsRaw <- subset(allCountsRaw, ! grepl("^TH06", sample_id)) # we don't have read type data for TH06
dim(na.omit(validCountsRaw))
# QC
nrow(validCountsRaw)
nrow(distinct(validCountsRaw))
nrow(distinct(validCountsRaw[,1:2]))
# Test for ambigous results
samples_with_ambigous_results <- validCountsRaw %>%
mutate(
sample_plus_count_type = paste0(sample_id, count_type),
has_ambigous_results = duplicated(sample_plus_count_type)
) %>%
#   filter(sample_id =="TH34_1349_S01") %>%
filter( has_ambigous_results) %>%
pull(sample_id) %>%
unique
# unambigous_counts <- allCountsRaw %>%
#   filter(! sample_id %in% samples_with_ambigous_results)
#
# any(is.na(unambigous_counts))
#
#
# # "TH34_1349_S01" %in% samples_without_ambigous_results
#
# groomed_read_survey_results <- spread(allCountsRaw, count_type, read_count)
# %>% write_tsv("groomed_read_survey_results_2019_03_28.txt")
log_dir <- "star_logs_2019_05_10"
mm_tibble <- lapply(list.files(log_dir), function(x) {
# x="THR33_1007_S01_Log.final.out"
f=file.path(log_dir, x)
raw_log <- scan(f, what="list", sep = "\n", quiet = TRUE)
mmreads_raw <- grep("Number of reads mapped to multiple loci", raw_log, value=TRUE)
mmreads <- as.numeric(gsub("^.*\t", "", mmreads_raw))
mm2reads_raw <- grep("Number of reads mapped to too many loci", raw_log, value=TRUE)
mm2reads <- as.numeric(gsub("^.*\t", "", mm2reads_raw))
tibble(sample_id = gsub("_Log.final.out", "", x),
multimappers = mmreads,
excessmultimappers = mm2reads)
}) %>% bind_rows
#
# read_counts <- allCountsRaw %>%
#   rename(UM = Uniquely_mapped_read_count,
#          UMND = Uniquely_mapped_non_duplicate_read_count)	%>%
#   mutate(pct_UMEND = UMEND / total_sequences,
#          Percent_duplicates = 1 - (UMND / UM)) %>%
#   dplyr::filter(!grepl("THR08", sample_id )) # i think duplicates may have been removed from these samples
# orderByTotalReads <- read_counts %>% arrange(desc(total_sequences)) %>%	.$sample_id
reads <- spread(validCountsRaw, count_type, read_count) %>%
left_join(mm_tibble, by="sample_id") %>%
arrange(desc(total_sequences)) %>%
mutate(not_uniquely_mapped = total_sequences - UM,
duplicate_reads = UM - UMND,
non_exonic_reads = UMND - UMEND,
sum_slices = UMEND + non_exonic_reads + duplicate_reads + not_uniquely_mapped,
UM2 = UM + multimappers,
not_uniquely_mapped2 = total_sequences - UM2,
duplicate_reads2 = UM2 - UMND,
illogic1 = duplicate_reads > not_uniquely_mapped,
illogic2 = duplicate_reads2 > not_uniquely_mapped2,
)
cor(reads$not_uniquely_mapped, reads$not_uniquely_mapped2)
ggplot(reads) + geom_point(aes(x=not_uniquely_mapped, y=not_uniquely_mapped2))
# ggplot(reads) + geom_histogram(aes(x=pct_multi_mappers))
## select afresh
n_samples_to_plot <- 50
selected_parent_samples <- tibble(THid = c("THR28_0688_S01",
"THR14_0298_S01",
"THR17_0392_S01",
"THR31_0892_S01",
"THR32_0941_S01"))
# smaller dataset to show individual samples
set.seed(1)
randomly_selected_samples <- reads %>%
filter(total_sequences < 150E6, # the most relevant set, and limiting makes plots intelligible
! sample_id %in% selected_parent_samples) %>%
sample_n(n_samples_to_plot-length(selected_parent_samples)) %>%
pull(sample_id)
samples_to_plot <- c(randomly_selected_samples, selected_parent_samples)
### use previously
samples_to_plot = scan("samples_to_plot.txt", what="list")
samples_to_plot
## select afresh
n_samples_to_plot <- 50
selected_parent_samples <- tibble(THid = c("THR28_0688_S01",
"THR14_0298_S01",
"THR17_0392_S01",
"THR31_0892_S01",
"THR32_0941_S01"))
# smaller dataset to show individual samples
set.seed(1)
randomly_selected_samples <- reads %>%
filter(total_sequences < 150E6, # the most relevant set, and limiting makes plots intelligible
! sample_id %in% selected_parent_samples) %>%
sample_n(n_samples_to_plot-length(selected_parent_samples)) %>%
pull(sample_id)
samples_to_plot <- c(randomly_selected_samples, selected_parent_samples)
### use previously
samples_to_plot = scan("samples_to_plot.txt", what="list")
small_plot_data <- reads %>%
filter(sample_id %in% samples_to_plot) %>%
select(sample_id, total_sequences, not_uniquely_mapped=not_uniquely_mapped2, duplicate_reads=duplicate_reads2, non_exonic_reads, UMEND) %>%
gather(read_type, read_count, not_uniquely_mapped, duplicate_reads, non_exonic_reads, UMEND) %>%
mutate(
sample_id = fct_reorder(sample_id, desc(total_sequences)),
read_type = factor(read_type, levels=raw_names_for_read_types)
)
#raw_names_for_read_types
#ggplot(barplot_data)
ggplot(small_plot_data) +
geom_bar(data = small_plot_data,
aes(x = sample_id,
y = read_count,
fill = read_type),
size = 1,
stat = "identity") +
scale_fill_manual("Read type", values = category_colors, labels=names(category_colors)) +
theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
legend.position = c(.4,.86))
#raw_names_for_read_types <-  c("not_uniquely_mapped", "duplicate_reads", "non_exonic_reads", "UMEND")
knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_knit$set(root.dir = "~/Documents/Dropbox/ucsc/projects/gitCode/drafts_of_umend_qc_publication/")
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(gridGraphics)
library(RColorBrewer)
library(viridis)
library(ggrepel)
library(cowplot)
library(janitor)
n_samples_to_plot <- 50
library(RColorBrewer)
source_palette <- brewer.pal(12, "Paired")
cb_dark_green <- source_palette[4]
cb_light_green <- source_palette[3]
raw_names_for_read_types <-  c("not_uniquely_mapped", "duplicate_reads", "non_exonic_reads", "UMEND")
intermediate_names_for_read_types = c("Not uniquely mapped", "Duplicate reads", "Non exonic reads", "UMEND")
better_names_for_read_types <- c("Not uniquely mapped", "Duplicate", "Non exonic", "UMEND")
category_colors <- c(grey(0.5), cb_light_green, grey(0.7), cb_dark_green)
names(category_colors) <- intermediate_names_for_read_types
allCountsRaw <- read_tsv(file.path( "../data/raw_read_survey_results_2019_03_28.txt"),
col_names = c("sample_id", "count_type", "read_count")) %>%
spread(count_type, read_count)
parent_sample_data <- read_tsv("../data/parent_sample_data_source.tsv") %>% rename(pub_ID = publication_id)
complete_counts_raw <- na.omit(allCountsRaw) %>%
filter(!grepl("TH06", sample_id)) # exclude placeholder QC values from TH06 (we don't have real QC values for these samples)
# consider excluding samples in which duplicates may have been removed
# dplyr::filter(!grepl("THR08", sample_id )) # i think duplicates may have been removed from these samples
# nrow (filter(allCountsRaw, grepl("THR08", sample_id )))
# effect of excluding NA, which are usually samples without four measurements
nrow(na.omit(allCountsRaw))
nrow((allCountsRaw))
read_counts <- complete_counts_raw %>%
rename(UM = Uniquely_mapped_read_count,
UMND = Uniquely_mapped_non_duplicate_read_count)
orderByTotalReads <- read_counts %>% arrange(desc(total_sequences)) %>%	.$sample_id
read_counts_with_slices <- read_counts %>%
arrange(desc(total_sequences)) %>%
mutate(pct_UMEND = UMEND / total_sequences,
Percent_duplicates = 1 - (UMND / UM),
not_uniquely_mapped = total_sequences - UM,
duplicate_reads = UM - UMND,
non_exonic_reads = UMND - UMEND,
sum_slices = UMEND + non_exonic_reads + duplicate_reads + not_uniquely_mapped)
plotInfo <- read_counts_with_slices %>%
select(sample_id,
not_uniquely_mapped,
duplicate_reads,
non_exonic_reads,
UMEND,
Percent_duplicates,
pct_UMEND,
total_sequences) %>%
gather(read_type, read_count, not_uniquely_mapped, duplicate_reads, non_exonic_reads, UMEND) %>%
mutate(read_type = intermediate_names_for_read_types[match(read_type, raw_names_for_read_types)],
read_type = factor(read_type,
levels = intermediate_names_for_read_types),
sample_id = factor(sample_id, levels = orderByTotalReads),
read_countM = read_count / 1e6,
percent_of_total = read_count / total_sequences)
# cat(small_plot_data %>% pull(sample_id) %>% unique %>% as.character, file="../data/samples_to_plot.txt")
# smaller dataset to show individual samples
read_counts_from_reasonably_sized_samples <- read_counts %>%
filter(total_sequences < 150E6) # the most relevant set, and limiting makes plots intelligible
selected_parent_samples <- tibble(THid = parent_sample_data$`Treehouse ID`)
# selected_parent_samples$plot_id = paste0("S", 1:nrow(selected_parent_samples))
selected_parent_samples$plot_id = "*"
n_random_samples_needed <- nrow(read_counts_from_reasonably_sized_samples) - nrow(selected_parent_samples)
set.seed(2)
random_samples <- read_counts_from_reasonably_sized_samples[sample(1:n_random_samples_needed,n_samples_to_plot),]$sample_id
samples_for_small_dataset <- c(selected_parent_samples$THid, random_samples)
# special_designation=c("other", "From_Fig1")
# special_designation <- c("", "*")
small_plot_data <- subset(plotInfo, sample_id %in% samples_for_small_dataset) %>%
mutate(highlight_text = selected_parent_samples$plot_id[match(sample_id, selected_parent_samples$THid)])
# small_plot_data$highlight_text = factor(special_designation[1 + small_plot_data$sample_id %in% example_samples_to_force_into_small_dataset],
#                                        levels = rev(special_designation))
selected_small_plot_data <- plotInfo %>%
dplyr::filter(sample_id %in% selected_parent_samples$THid)
# cat(small_plot_data %>% pull(sample_id) %>% unique %>% as.character, file="../data/samples_to_plot.txt")
read_type_mean_and_sd_20U <- plotInfo %>%
group_by(sample_id) %>%
dplyr::filter(read_countM[read_type == "UMEND"] > 20) %>%
group_by(read_type) %>%
summarize(mean_pct_of_total = mean(percent_of_total),
one_sd = sd(percent_of_total),
mean_minus_one_sd = mean_pct_of_total - one_sd,
mean_plus_one_sd = mean_pct_of_total + one_sd,
mean_minus_two_sd = mean_pct_of_total - one_sd * 2,
mean_plus_two_sd = mean_pct_of_total + one_sd * 2) %>%
gather(stat, value, -one_sd, -read_type) %>%
mutate(stat2 = gsub("^.*two_sd", "two_sd", gsub("^.*one_sd", "one_sd", stat)))
read_types_with_a_lower_bound <- c("UMEND", "Duplicate reads")
read_type_pct_thresholds_raw <- read_type_mean_and_sd_20U %>%
dplyr::filter(grepl("two_sd", stat)) %>%
mutate(value2 = ifelse(grepl("minus_two_sd", stat),
ifelse(read_type %in% read_types_with_a_lower_bound,
value,
0),
value))
#
# read_type_pct_thresholds <- read_type_pct_thresholds_raw %>%
#  select(read_type, stat, value2) %>%
#   spread(stat, value2) %>%
#   rename(min_pct = mean_minus_two_sd, max_pct = mean_plus_two_sd)
read_type_pct_thresholds <- read_type_pct_thresholds_raw %>%
select(read_type, stat, value) %>%
spread(stat, value) %>%
rename(min_pct = mean_minus_two_sd, max_pct = mean_plus_two_sd)
plot_info_with_limits <- left_join(plotInfo, read_type_pct_thresholds, by = "read_type") %>%
mutate(within_limits = ifelse(percent_of_total > min_pct,
ifelse(percent_of_total<max_pct,
"within_limits",
"above_limit"),
"below_limit"))
samples_within_read_type_limits <- plot_info_with_limits %>%
group_by(sample_id) %>%
filter(sum(grepl("within_limits", within_limits)) == 4) %>%
pull(sample_id) %>% unique
length(unique(plot_info_with_limits$sample_id))
length(samples_within_read_type_limits)
length(samples_within_read_type_limits)/length(unique(plot_info_with_limits$sample_id))
depth_status <- read_counts_with_slices %>%
select(sample_id, UMEND) %>%
mutate(
status=ifelse( UMEND<10E6,
"<10M_UMEND_reads",
ifelse(UMEND<20E6,
"10<UMEND_reads<20",
">20M_UMEND_reads")
),
all_read_types_within_read_type_limits = sample_id %in% samples_within_read_type_limits,
within_read_type_limits_label = c( "not_WNL", "WNL")[1 + all_read_types_within_read_type_limits]
)
tabyl(depth_status, within_read_type_limits_label, status)
plot_info_with_limits2 <- plot_info_with_limits %>% left_join(depth_status, by="sample_id")
table(plot_info_with_limits2$within_limits)
plot_info_for_problem_samples <- plot_info_with_limits2 %>%
filter( ! (status==">20M_UMEND_reads" & all_read_types_within_read_type_limits)) %>%
group_by(status, within_read_type_limits_label) %>%
mutate(
depth_status_label = paste0(within_read_type_limits_label, ",", status, " (n=", length(unique(sample_id)), ")" ))
nrow(plot_info_for_problem_samples)/4
ggplot(plot_info_for_problem_samples) +
geom_tile(aes(x=read_type,
y=sample_id,
fill=within_limits)) +
facet_grid(depth_status_label ~ ., scales="free_y", space="free",
labeller = label_wrap_gen(width = 8, multi_line = TRUE)) +
#facet_wrap(~depth_status_label, ncol=1, scales="free_y") +
scale_fill_brewer(palette = "Set1") +
theme(strip.text.y = element_text(angle = 0),
axis.text.y = element_blank())
small_plot_data$not_WNL <- small_plot_data$sample_id  %in% samples_within_read_type_limits
threshold_codes=c("NUM"="Not uniquely mapped", "D"="Duplicate reads", "NE" = "Non exonic reads", "U" = "UMEND")
threshold_failure_notes <- subset(plot_info_with_limits, sample_id  %in% subset(small_plot_data, ! not_WNL)$sample_id) %>%
filter(within_limits != "within_limits") %>%
mutate(threshold_code = names(threshold_codes)[match(read_type, threshold_codes)]) %>%
group_by(sample_id, total_sequences) %>%
summarize(failed_thresholds = paste(threshold_code, collapse=", "))
# to review visually
subset(plot_info_with_limits, sample_id  %in% subset(small_plot_data, ! not_WNL)$sample_id) %>%
filter(within_limits != "within_limits") %>%
select(sample_id, read_type, within_limits) %>%
spread(read_type, within_limits)
# of the samples i've looked at, a below threshold UMEND value is always accompanied by a value that exceeds the threshold in another category
# includes all samples
min_UMEND = 20 * 1e6
adjusted_read_counts <- plotInfo %>%
group_by(sample_id) %>%
mutate(adjustment_factor = 1 / (read_count[read_type == "UMEND"]/min_UMEND),
adjust_read_count = adjustment_factor * read_count,
total_adjusted_read_count = sum(adjust_read_count))
# includes only samples within the reference ranges
proposed_thresholds = c(1,seq(4,48, by = 4))
percentiles_to_query = 0.95 # c(50, 75, 95, 100)/100
#library(purrr)
# remove failed samples
plot_info_within_limits <- plotInfo %>%
filter(sample_id %in% samples_within_read_type_limits)
proposed_threshold=1
percentile_to_query=0.95
rescale_and_get_percentile <- function(proposed_threshold, percentile_to_query) {
plot_info_within_limits %>%
filter(read_type == "UMEND") %>%
mutate(adjustment_factor = 1 / (read_count / (proposed_threshold * 1e6)),
adjusted_total = adjustment_factor * total_sequences) %>%
pull(adjusted_total) %>%
quantile(percentile_to_query)
}
predictions <- NULL
for (proposed_threshold in proposed_thresholds) {
for (percentile_to_query in percentiles_to_query){
predictions <- bind_rows(predictions,
tibble(proposed_threshold,
percentile_to_query,
predicted_total_reads = rescale_and_get_percentile(proposed_threshold,
percentile_to_query)))
}
}
write_tsv(predictions %>% filter(percentile_to_query==0.95),
"../data/predicted_required_total_reads_within_limits.tsv")
plot_title <- "Total number of reads in a sample does not predict the number of UMEND reads"
figure_name <- "read_count_and_fractions_figures_v2"
# note negative values in small_plot_data$read_countM, e.g. -0.4817530
p1 <- ggplot(small_plot_data) +
geom_bar(data = small_plot_data,
aes(x = sample_id,
y = read_countM,
fill = read_type),
size = 1,
stat = "identity") +
scale_fill_manual("Read type", values = category_colors, labels=better_names_for_read_types) +
scale_color_grey(end = 0.6) +
# facet_grid(.~highlight_sample, scales="free_x", space="free") +
xlab(paste0("Samples, n=", length(samples_for_small_dataset))) +
ylab("Read count (millions)") +
#  ylim(0, 175) +
geom_text(data=subset(small_plot_data, read_type == "UMEND"),
aes(x = sample_id,
y = 1 + total_sequences / 1e6,
label = highlight_text),
color = "black",
size = 5) +
geom_text(data=threshold_failure_notes,
aes(x = sample_id,
y = 1 + total_sequences / 1e6,
label = failed_thresholds),
angle=90, hjust=0,
color = "darkred",
size=3) +
# labs(caption= paste(figure_name, Sys.time())) +
theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
#           legend.position = c(.4,.86)
legend.position = c(0.65, 0.8)
#   plot.caption = element_text(hjust = -1)
)
#geom_text(data=selected_small_plot_data, aes(x=sample_id, y=total_sequences), label="*")
p1
